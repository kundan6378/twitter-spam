{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0r3P7rKJP9l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NPRocy8XbKE",
        "outputId": "9dd88e3c-5701-42dd-e590-9f8d4d94509d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mzzIY8RJjOd",
        "outputId": "05bdbc1e-3fe3-49a0-87b3-7b8731513c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yJODEF3QwWI",
        "outputId": "a4f2e7ac-4bea-44b1-958e-8c291f83e67e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the data\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'  # Adjust this path as per your directory structure\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spyOVWIRUccP",
        "outputId": "91dcefda-1aee-4333-fc0f-7a5375a7dd93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   UserID            CreatedAt          CollectedAt  NumberOfFollowings  \\\n",
            "0    6301  2006-09-18 01:07:50  2010-01-17 20:38:25                3269   \n",
            "1   10836  2006-10-27 14:38:04  2010-06-18 03:35:34                1949   \n",
            "2   10997  2006-10-29 09:50:38  2010-04-24 01:12:40                1119   \n",
            "3  633293  2007-01-14 12:40:10  2010-01-24 11:59:38                2174   \n",
            "4  717883  2007-01-27 22:14:18  2010-02-06 06:25:58                7731   \n",
            "\n",
            "   NumberOfFollowers  NumberOfTweets  LengthOfScreenName  \\\n",
            "0               3071             861                   8   \n",
            "1                793             226                   9   \n",
            "2               9644           38674                  12   \n",
            "3               6029           12718                  11   \n",
            "4               7029             873                   6   \n",
            "\n",
            "   LengthOfDescriptionInUserProfile Label  \n",
            "0                               132  spam  \n",
            "1                               134  spam  \n",
            "2                               158  spam  \n",
            "3                               121  spam  \n",
            "4                                70  spam  \n",
            "   UserID                         SeriesOfNumberOfFollowings\n",
            "0    6301  3269,3310,3339,3381,3351,3323,3305,3275,3245,3...\n",
            "1   10836  1949,1963,1963,1963,1963,1963,1963,1962,1961,1...\n",
            "2   10997  1119,1119,999,999,1050,1170,1071,799,799,799,8...\n",
            "3  633293  2174,2651,2676,2674,2673,2673,2673,2672,2672,2...\n",
            "4  717883  7731,7737,7737,7741,7741,7741,7740,7740,7749,7...\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt  \n",
            "0  2009-11-10 15:14:31  \n",
            "1  2009-11-10 15:46:05  \n",
            "2  2009-11-10 15:46:40  \n",
            "3  2009-11-10 15:47:03  \n",
            "4  2009-11-10 15:56:03  \n"
          ]
        }
      ],
      "source": [
        "content_polluters = pd.read_csv(os.path.join(data_dir, 'content_polluters.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'CreatedAt', 'CollectedAt', 'NumberOfFollowings', 'NumberOfFollowers',\n",
        "    'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile'])\n",
        "\n",
        "content_polluters_followings = pd.read_csv(os.path.join(data_dir, 'content_polluters_followings.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'SeriesOfNumberOfFollowings'])\n",
        "\n",
        "content_polluters_tweets = pd.read_csv(os.path.join(data_dir, 'content_polluters_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "legitimate_users = pd.read_csv(os.path.join(data_dir, 'legitimate_users.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'CreatedAt', 'CollectedAt', 'NumberOfFollowings', 'NumberOfFollowers',\n",
        "    'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile'])\n",
        "\n",
        "legitimate_users_followings = pd.read_csv(os.path.join(data_dir, 'legitimate_users_followings.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'SeriesOfNumberOfFollowings'])\n",
        "\n",
        "legitimate_users_tweets = pd.read_csv(os.path.join(data_dir, 'legitimate_users_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "# Add labels: content polluters as 'spam' and legitimate users as 'ham'\n",
        "content_polluters['Label'] = 'spam'\n",
        "legitimate_users['Label'] = 'ham'\n",
        "\n",
        "# Combine user profile data\n",
        "user_profiles = pd.concat([content_polluters, legitimate_users], ignore_index=True)\n",
        "\n",
        "# Combine followings data\n",
        "followings = pd.concat([content_polluters_followings, legitimate_users_followings], ignore_index=True)\n",
        "\n",
        "# Combine tweets data\n",
        "tweets = pd.concat([content_polluters_tweets, legitimate_users_tweets], ignore_index=True)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(user_profiles.head())\n",
        "print(followings.head())\n",
        "print(tweets.head())\n",
        "\n",
        "# Convert dates to datetime in user_profiles\n",
        "user_profiles['CreatedAt'] = pd.to_datetime(user_profiles['CreatedAt'], errors='coerce')\n",
        "user_profiles['CollectedAt'] = pd.to_datetime(user_profiles['CollectedAt'], errors='coerce')\n",
        "tweets['CreatedAt'] = pd.to_datetime(tweets['CreatedAt'], errors='coerce')\n",
        "\n",
        "# Calculate the frequency of tweets (tweets per day)\n",
        "user_profiles['AccountAgeDays'] = (user_profiles['CollectedAt'] - user_profiles['CreatedAt']).dt.days\n",
        "user_profiles['TweetsPerDay'] = user_profiles['NumberOfTweets'] / user_profiles['AccountAgeDays']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXkzKhnPUoiu",
        "outputId": "aaad1a51-310d-4e81-a7e5-9152a73680ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed chunk 0 saved.\n",
            "Processed chunk 1 saved.\n",
            "Processed chunk 2 saved.\n",
            "Processed chunk 3 saved.\n",
            "Processed chunk 4 saved.\n",
            "Processed chunk 5 saved.\n",
            "Processed chunk 6 saved.\n",
            "Processed chunk 7 saved.\n",
            "Processed chunk 8 saved.\n",
            "Processed chunk 9 saved.\n",
            "Processed chunk 10 saved.\n",
            "Processed chunk 11 saved.\n",
            "Processed chunk 12 saved.\n",
            "Processed chunk 13 saved.\n",
            "Processed chunk 14 saved.\n",
            "Processed chunk 15 saved.\n",
            "Processed chunk 16 saved.\n",
            "Processed chunk 17 saved.\n",
            "Processed chunk 18 saved.\n",
            "Processed chunk 19 saved.\n",
            "Processed chunk 20 saved.\n",
            "Processed chunk 21 saved.\n",
            "Processed chunk 22 saved.\n",
            "Processed chunk 23 saved.\n",
            "Processed chunk 24 saved.\n",
            "Processed chunk 25 saved.\n",
            "Processed chunk 26 saved.\n",
            "Processed chunk 27 saved.\n",
            "Processed chunk 28 saved.\n",
            "Processed chunk 29 saved.\n",
            "Processed chunk 30 saved.\n",
            "Processed chunk 31 saved.\n",
            "Processed chunk 32 saved.\n",
            "Processed chunk 33 saved.\n",
            "Processed chunk 34 saved.\n",
            "Processed chunk 35 saved.\n",
            "Processed chunk 36 saved.\n",
            "Processed chunk 37 saved.\n",
            "Processed chunk 38 saved.\n",
            "Processed chunk 39 saved.\n",
            "Processed chunk 40 saved.\n",
            "Processed chunk 41 saved.\n",
            "Processed chunk 42 saved.\n",
            "Processed chunk 43 saved.\n",
            "Processed chunk 44 saved.\n",
            "Processed chunk 45 saved.\n",
            "Processed chunk 46 saved.\n",
            "Processed chunk 47 saved.\n",
            "Processed chunk 48 saved.\n",
            "Processed chunk 49 saved.\n",
            "Processed chunk 50 saved.\n",
            "Processed chunk 51 saved.\n",
            "Processed chunk 52 saved.\n",
            "Processed chunk 53 saved.\n",
            "Processed chunk 54 saved.\n",
            "Processed chunk 55 saved.\n",
            "Processed chunk 56 saved.\n",
            "Processed chunk 57 saved.\n",
            "Processed chunk 58 saved.\n",
            "Processed chunk 59 saved.\n",
            "Processed chunk 60 saved.\n",
            "Processed chunk 61 saved.\n",
            "Processed chunk 62 saved.\n",
            "Processed chunk 63 saved.\n",
            "Processed chunk 64 saved.\n",
            "Processed chunk 65 saved.\n",
            "Processed chunk 66 saved.\n",
            "Processed chunk 67 saved.\n",
            "Processed chunk 68 saved.\n",
            "Processed chunk 69 saved.\n",
            "Processed chunk 70 saved.\n",
            "Processed chunk 71 saved.\n",
            "Processed chunk 72 saved.\n",
            "Processed chunk 73 saved.\n",
            "Processed chunk 74 saved.\n",
            "Processed chunk 75 saved.\n",
            "Processed chunk 76 saved.\n",
            "Processed chunk 77 saved.\n",
            "Processed chunk 78 saved.\n",
            "Processed chunk 79 saved.\n",
            "Processed chunk 80 saved.\n",
            "Processed chunk 81 saved.\n",
            "Processed chunk 82 saved.\n",
            "Processed chunk 83 saved.\n",
            "Processed chunk 84 saved.\n",
            "Processed chunk 85 saved.\n",
            "Processed chunk 86 saved.\n",
            "Processed chunk 87 saved.\n",
            "Processed chunk 88 saved.\n",
            "Processed chunk 89 saved.\n",
            "Processed chunk 90 saved.\n",
            "Processed chunk 91 saved.\n",
            "Processed chunk 92 saved.\n",
            "Processed chunk 93 saved.\n",
            "Processed chunk 94 saved.\n",
            "Processed chunk 95 saved.\n",
            "Processed chunk 96 saved.\n",
            "Processed chunk 97 saved.\n",
            "Processed chunk 98 saved.\n",
            "Processed chunk 99 saved.\n",
            "Processed chunk 100 saved.\n",
            "Processed chunk 101 saved.\n",
            "Processed chunk 102 saved.\n",
            "Processed chunk 103 saved.\n",
            "Processed chunk 104 saved.\n",
            "Processed chunk 105 saved.\n",
            "Processed chunk 106 saved.\n",
            "Processed chunk 107 saved.\n",
            "Processed chunk 108 saved.\n",
            "Processed chunk 109 saved.\n",
            "Processed chunk 110 saved.\n",
            "Processed chunk 111 saved.\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt Label  \\\n",
            "0  2009-11-10 15:14:31  spam   \n",
            "1  2009-11-10 15:46:05  spam   \n",
            "2  2009-11-10 15:46:40  spam   \n",
            "3  2009-11-10 15:47:03  spam   \n",
            "4  2009-11-10 15:56:03  spam   \n",
            "\n",
            "                                          CleanTweet  TweetLength  \\\n",
            "0  MELBOURNE ENQUIRY Seeking variety acts end yea...           77   \n",
            "1  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "2  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "3  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "4  Come Burlesque Bootcamp Sydney Saturday 23 Jan...           86   \n",
            "\n",
            "                                     SentimentScores  neg  neu  pos  compound  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n"
          ]
        }
      ],
      "source": [
        "# Preprocess tweets: Clean the text\n",
        "STOPWORDS = set(stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    if pd.isnull(tweet):  # Check if the tweet is NaN\n",
        "        return \"\"\n",
        "    tweet = str(tweet)  # Convert to string\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)  # Remove URLs\n",
        "    tweet = re.sub(r\"@\\S+\", \"\", tweet)  # Remove mentions\n",
        "    tweet = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", tweet)  # Remove special characters\n",
        "    tweet = ' '.join([word for word in tweet.split() if word.lower() not in STOPWORDS])\n",
        "    return tweet\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define chunk size\n",
        "chunk_size = 50000  # Adjust the chunk size based on available memory\n",
        "\n",
        "# Function to process a chunk of data\n",
        "def process_chunk(chunk, chunk_id, save_dir):\n",
        "    # Merge chunk with user profiles to add Label\n",
        "    chunk = pd.merge(chunk, user_profiles[['UserID', 'Label']], on='UserID', how='left')\n",
        "\n",
        "    chunk['CleanTweet'] = chunk['Tweet'].apply(clean_tweet)\n",
        "    chunk['TweetLength'] = chunk['CleanTweet'].apply(len)\n",
        "    chunk['SentimentScores'] = chunk['CleanTweet'].apply(analyzer.polarity_scores)\n",
        "\n",
        "    # Expand sentiment scores into separate columns\n",
        "    sentiment_df = chunk['SentimentScores'].apply(pd.Series)\n",
        "    chunk = pd.concat([chunk, sentiment_df], axis=1)\n",
        "\n",
        "    # Save the chunk to a file\n",
        "    chunk.to_csv(os.path.join(save_dir, f'processed_chunk_{chunk_id}.csv'), index=False)\n",
        "    print(f\"Processed chunk {chunk_id} saved.\")\n",
        "\n",
        "# Directory to save processed chunks\n",
        "save_directory = data_dir  # Save in the same directory as input files\n",
        "\n",
        "# Process and save chunks for content polluters tweets (spam)\n",
        "chunk_id = 0\n",
        "for chunk in pd.read_csv(os.path.join(data_dir, 'content_polluters_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'], chunksize=chunk_size):\n",
        "    process_chunk(chunk, chunk_id, save_directory)\n",
        "    chunk_id += 1\n",
        "\n",
        "# Process and save chunks for legitimate users tweets (ham)\n",
        "for chunk in pd.read_csv(os.path.join(data_dir, 'legitimate_users_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'], chunksize=chunk_size):\n",
        "    process_chunk(chunk, chunk_id, save_directory)\n",
        "    chunk_id += 1\n",
        "\n",
        "# Combine all processed chunks into a single DataFrame if needed\n",
        "chunk_files = [os.path.join(save_directory, f'processed_chunk_{i}.csv') for i in range(chunk_id)]\n",
        "combined_df = pd.concat((pd.read_csv(f) for f in chunk_files), ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined DataFrame\n",
        "print(combined_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq6fJUdppF7u",
        "outputId": "81fa3fb4-6d22-4ddb-b6d2-1c3470d0c6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total original tweets: 5579687\n",
            "Total processed tweets: 5579352\n",
            "Number of removed tweets: 335\n",
            "Percentage of removed tweets: 0.01%\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "\n",
        "# # Directory containing the processed chunk files\n",
        "# data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# # List all files in the directory\n",
        "# all_files = os.listdir(data_dir)\n",
        "\n",
        "# # Filter out the processed chunk files\n",
        "# chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# # Load all the chunk files and concatenate them into a single DataFrame\n",
        "# processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# # Remove duplicates from processed tweets\n",
        "# processed_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "\n",
        "# # Load original data and count total number of tweets\n",
        "# original_polluters_tweets = pd.read_csv(os.path.join(data_dir, 'content_polluters_tweets.txt'), sep='\\t', header=None, names=['UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "# original_legitimate_tweets = pd.read_csv(os.path.join(data_dir, 'legitimate_users_tweets.txt'), sep='\\t', header=None, names=['UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "# # Remove duplicates from original tweets\n",
        "# original_polluters_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "# original_legitimate_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "\n",
        "# total_original_tweets = len(original_polluters_tweets) + len(original_legitimate_tweets)\n",
        "\n",
        "# # Count the number of tweets in the processed DataFrame\n",
        "# total_processed_tweets = len(processed_tweets)\n",
        "\n",
        "# # Calculate the number and percentage of removed tweets\n",
        "# removed_tweets = total_original_tweets - total_processed_tweets\n",
        "# removed_percentage = (removed_tweets / total_original_tweets) * 100\n",
        "\n",
        "# print(f\"Total original tweets: {total_original_tweets}\")\n",
        "# print(f\"Total processed tweets: {total_processed_tweets}\")\n",
        "# print(f\"Number of removed tweets: {removed_tweets}\")\n",
        "# print(f\"Percentage of removed tweets: {removed_percentage:.2f}%\")\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# Load all the chunk files and concatenate them into a single DataFrame\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# Remove duplicates from processed tweets\n",
        "processed_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "\n",
        "# Remove empty tweets\n",
        "processed_tweets = processed_tweets[processed_tweets['Tweet'].str.strip().astype(bool)]\n",
        "processed_tweets = processed_tweets[processed_tweets['CleanTweet'].str.strip().astype(bool)]\n",
        "\n",
        "# Load original data and count total number of tweets\n",
        "original_polluters_tweets = pd.read_csv(os.path.join(data_dir, 'content_polluters_tweets.txt'), sep='\\t', header=None, names=['UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "original_legitimate_tweets = pd.read_csv(os.path.join(data_dir, 'legitimate_users_tweets.txt'), sep='\\t', header=None, names=['UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "# Remove duplicates from original tweets\n",
        "original_polluters_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "original_legitimate_tweets.drop_duplicates(subset=['UserID', 'TweetID'], inplace=True)\n",
        "\n",
        "# Remove empty tweets from original data\n",
        "original_polluters_tweets = original_polluters_tweets[original_polluters_tweets['Tweet'].str.strip().astype(bool)]\n",
        "original_legitimate_tweets = original_legitimate_tweets[original_legitimate_tweets['Tweet'].str.strip().astype(bool)]\n",
        "\n",
        "total_original_tweets = len(original_polluters_tweets) + len(original_legitimate_tweets)\n",
        "\n",
        "# Count the number of tweets in the processed DataFrame\n",
        "total_processed_tweets = len(processed_tweets)\n",
        "\n",
        "# Calculate the number and percentage of removed tweets\n",
        "removed_tweets = total_original_tweets - total_processed_tweets\n",
        "removed_percentage = (removed_tweets / total_original_tweets) * 100\n",
        "\n",
        "print(f\"Total original tweets: {total_original_tweets}\")\n",
        "print(f\"Total processed tweets: {total_processed_tweets}\")\n",
        "print(f\"Number of removed tweets: {removed_tweets}\")\n",
        "print(f\"Percentage of removed tweets: {removed_percentage:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOyncZ7QVFS7",
        "outputId": "21f69c9f-7d22-4ac7-b4e4-6598101dfd8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the processed tweets:\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt Label  \\\n",
            "0  2009-11-10 15:14:31  spam   \n",
            "1  2009-11-10 15:46:05  spam   \n",
            "2  2009-11-10 15:46:40  spam   \n",
            "3  2009-11-10 15:47:03  spam   \n",
            "4  2009-11-10 15:56:03  spam   \n",
            "\n",
            "                                          CleanTweet  TweetLength  \\\n",
            "0  MELBOURNE ENQUIRY Seeking variety acts end yea...           77   \n",
            "1  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "2  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "3  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "4  Come Burlesque Bootcamp Sydney Saturday 23 Jan...           86   \n",
            "\n",
            "                                     SentimentScores  neg  neu  pos  compound  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# Load user profiles (assuming this DataFrame is already loaded in your environment)\n",
        "# user_profiles = ...\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Directory containing the dataset files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'  # Adjust this path as per your directory structure\n",
        "\n",
        "# Load the data\n",
        "content_polluters = pd.read_csv(os.path.join(data_dir, 'content_polluters.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'CreatedAt', 'CollectedAt', 'NumberOfFollowings', 'NumberOfFollowers',\n",
        "    'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile'])\n",
        "\n",
        "content_polluters_followings = pd.read_csv(os.path.join(data_dir, 'content_polluters_followings.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'SeriesOfNumberOfFollowings'])\n",
        "\n",
        "content_polluters_tweets = pd.read_csv(os.path.join(data_dir, 'content_polluters_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "legitimate_users = pd.read_csv(os.path.join(data_dir, 'legitimate_users.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'CreatedAt', 'CollectedAt', 'NumberOfFollowings', 'NumberOfFollowers',\n",
        "    'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile'])\n",
        "\n",
        "legitimate_users_followings = pd.read_csv(os.path.join(data_dir, 'legitimate_users_followings.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'SeriesOfNumberOfFollowings'])\n",
        "\n",
        "legitimate_users_tweets = pd.read_csv(os.path.join(data_dir, 'legitimate_users_tweets.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'TweetID', 'Tweet', 'CreatedAt'])\n",
        "\n",
        "# Add labels: content polluters as 'spam' and legitimate users as 'ham'\n",
        "content_polluters['Label'] = 'spam'\n",
        "legitimate_users['Label'] = 'ham'\n",
        "\n",
        "# Combine user profile data\n",
        "user_profiles = pd.concat([content_polluters, legitimate_users], ignore_index=True)\n",
        "\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# Load all the chunk files and concatenate them into a single DataFrame\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of the processed tweets:\")\n",
        "print(processed_tweets.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uCOrTzB9S05"
      },
      "source": [
        "Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3JYAcDs87w3",
        "outputId": "6bac2269-fcd3-46d3-fedb-82e5ad69554b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-964e3654d1a6>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final features DataFrame:\n",
            "   NumberOfFollowings  NumberOfFollowers  NumberOfTweets  LengthOfScreenName  \\\n",
            "0                3269               3071             861                   8   \n",
            "1                3269               3071             861                   8   \n",
            "2                3269               3071             861                   8   \n",
            "3                3269               3071             861                   8   \n",
            "4                3269               3071             861                   8   \n",
            "\n",
            "   LengthOfDescriptionInUserProfile  TweetLength  neg  neu  pos  compound  \\\n",
            "0                               132           77  0.0  1.0  0.0       0.0   \n",
            "1                               132           57  0.0  1.0  0.0       0.0   \n",
            "2                               132           57  0.0  1.0  0.0       0.0   \n",
            "3                               132           57  0.0  1.0  0.0       0.0   \n",
            "4                               132           86  0.0  1.0  0.0       0.0   \n",
            "\n",
            "  Label_x  Label_num  \n",
            "0    spam          1  \n",
            "1    spam          1  \n",
            "2    spam          1  \n",
            "3    spam          1  \n",
            "4    spam          1  \n",
            "\n",
            "Checking for NaN and infinity values in features...\n",
            "\n",
            "Number of NaN values in each column of X before imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n",
            "\n",
            "Number of NaN values in each column of X after imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming user_profiles and processed_tweets DataFrames are already loaded\n",
        "\n",
        "# Merge processed tweets with user profiles to include labels and user information\n",
        "tweet_features = pd.merge(processed_tweets, user_profiles, on='UserID', how='left')\n",
        "\n",
        "# Adjust the feature columns based on the available columns in the DataFrame\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile', 'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound', 'Label_x']\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "final_features = tweet_features[[col for col in feature_columns if col in tweet_features.columns]]\n",
        "\n",
        "# Map labels to numerical values if 'Label_x' is available\n",
        "if 'Label_x' in final_features.columns:\n",
        "    final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n",
        "    label_available = True\n",
        "else:\n",
        "    print(\"Warning: 'Label_x' column is missing, cannot map to numerical values.\")\n",
        "    label_available = False\n",
        "\n",
        "# Display the first few rows of the final features\n",
        "print(\"\\nFinal features DataFrame:\")\n",
        "print(final_features.head())\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = final_features.drop(['Label_x', 'Label_num'], axis=1, errors='ignore')\n",
        "y = final_features['Label_num'] if label_available else None\n",
        "\n",
        "# Check for NaN and infinite values\n",
        "print(\"\\nChecking for NaN and infinity values in features...\")\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column\n",
        "print(\"\\nNumber of NaN values in each column of X before imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Fill NaN values with column means\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column after imputation\n",
        "print(\"\\nNumber of NaN values in each column of X after imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Proceed with splitting only if labels are available\n",
        "if label_available:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "else:\n",
        "    print(\"Skipping model training and evaluation due to missing labels.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZCHzjv39XpT"
      },
      "source": [
        "Evaluation function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytwb3CyQ9dmk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, y_pred, training_time):\n",
        "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "    print(\"Training Time:\", training_time)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Create a DataFrame to display predictions and actual labels\n",
        "    evaluation_df = pd.DataFrame({\n",
        "        'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "        'Actual Label': y_test,\n",
        "        'Predicted Label': y_pred\n",
        "    })\n",
        "\n",
        "    # Map numerical labels back to original labels for readability\n",
        "    label_map = {0: 'ham', 1: 'spam'}\n",
        "    evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "    evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "    # Display a sample of the evaluated data\n",
        "    print(\"\\nSample of Evaluated Data:\")\n",
        "    print(evaluation_df.head(10))  # Display the first 10 rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD-pS5fekyLp"
      },
      "source": [
        "Adaboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7RRWJXIk0Qn",
        "outputId": "e0aa0e72-98b1-4c95-a185-86831e674f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training AdaBoost with params: {'n_estimators': 50}...\n",
            "\n",
            "Evaluating AdaBoost with params: {'n_estimators': 50}...\n",
            "\n",
            "Model: AdaBoostClassifier\n",
            "Training Time: 400.48941946029663\n",
            "Accuracy: 0.8899570017294071\n",
            "Precision: 0.8578824491790273\n",
            "Recall: 0.8837038984982285\n",
            "F1 Score: 0.8706017543187651\n",
            "AUC-ROC: 0.8890843580135948\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90    981142\n",
            "           1       0.86      0.88      0.87    707298\n",
            "\n",
            "    accuracy                           0.89   1688440\n",
            "   macro avg       0.89      0.89      0.89   1688440\n",
            "weighted avg       0.89      0.89      0.89   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[877597 103545]\n",
            " [ 82256 625042]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training AdaBoost with params: {'n_estimators': 100}...\n",
            "\n",
            "Evaluating AdaBoost with params: {'n_estimators': 100}...\n",
            "\n",
            "Model: AdaBoostClassifier\n",
            "Training Time: 616.871246099472\n",
            "Accuracy: 0.8930438748193599\n",
            "Precision: 0.8618207647360272\n",
            "Recall: 0.8868737081117153\n",
            "F1 Score: 0.8741677739787355\n",
            "AUC-ROC: 0.8921828052025825\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91    981142\n",
            "           1       0.86      0.89      0.87    707298\n",
            "\n",
            "    accuracy                           0.89   1688440\n",
            "   macro avg       0.89      0.89      0.89   1688440\n",
            "weighted avg       0.89      0.89      0.89   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[880567 100575]\n",
            " [ 80014 627284]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training AdaBoost with params: {'n_estimators': 200}...\n",
            "\n",
            "Evaluating AdaBoost with params: {'n_estimators': 200}...\n",
            "\n",
            "Model: AdaBoostClassifier\n",
            "Training Time: 1296.544953584671\n",
            "Accuracy: 0.8946518679964938\n",
            "Precision: 0.8645728892365664\n",
            "Recall: 0.8875410364513967\n",
            "F1 Score: 0.8759064201827002\n",
            "AUC-ROC: 0.8936595251176671\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91    981142\n",
            "           1       0.86      0.89      0.88    707298\n",
            "\n",
            "    accuracy                           0.89   1688440\n",
            "   macro avg       0.89      0.89      0.89   1688440\n",
            "weighted avg       0.90      0.89      0.89   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[882810  98332]\n",
            " [ 79542 627756]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define hyperparameters for AdaBoost\n",
        "ada_hyperparameters = [{'n_estimators': 50}, {'n_estimators': 100}, {'n_estimators': 200}]\n",
        "\n",
        "# Train and evaluate AdaBoost with specified hyperparameters\n",
        "for params in ada_hyperparameters:\n",
        "    print(f\"\\nTraining AdaBoost with params: {params}...\")\n",
        "    model = AdaBoostClassifier(**params, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating AdaBoost with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz0tvzrlk2OO"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy3Mk1Ivk5QW",
        "outputId": "5b7ddef9-6f80-4d95-b6b8-38c9282925eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DecisionTree with params: {'max_depth': None}...\n",
            "\n",
            "Evaluating DecisionTree with params: {'max_depth': None}...\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Training Time: 48.398414850234985\n",
            "Accuracy: 0.9915347895098434\n",
            "Precision: 0.9911424898264075\n",
            "Recall: 0.9886271416008529\n",
            "F1 Score: 0.9898832178063294\n",
            "AUC-ROC: 0.9911290164749568\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[974893   6249]\n",
            " [  8044 699254]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training DecisionTree with params: {'max_depth': 10}...\n",
            "\n",
            "Evaluating DecisionTree with params: {'max_depth': 10}...\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Training Time: 30.466246128082275\n",
            "Accuracy: 0.9169772097320603\n",
            "Precision: 0.8872404087635898\n",
            "Recall: 0.9185491829469332\n",
            "F1 Score: 0.9026233801417798\n",
            "AUC-ROC: 0.9171965844163842\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93    981142\n",
            "           1       0.89      0.92      0.90    707298\n",
            "\n",
            "    accuracy                           0.92   1688440\n",
            "   macro avg       0.91      0.92      0.92   1688440\n",
            "weighted avg       0.92      0.92      0.92   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[898573  82569]\n",
            " [ 57610 649688]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958              ham  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training DecisionTree with params: {'max_depth': 20}...\n",
            "\n",
            "Evaluating DecisionTree with params: {'max_depth': 20}...\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Training Time: 51.36508798599243\n",
            "Accuracy: 0.9888210419085073\n",
            "Precision: 0.982061254185684\n",
            "Recall: 0.991423699770111\n",
            "F1 Score: 0.9867202687043696\n",
            "AUC-ROC: 0.9891842524526757\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.98      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[968333  12809]\n",
            " [  6066 701232]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347               ham  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training DecisionTree with params: {'max_depth': 30}...\n",
            "\n",
            "Evaluating DecisionTree with params: {'max_depth': 30}...\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Training Time: 45.284345626831055\n",
            "Accuracy: 0.9920346592120537\n",
            "Precision: 0.9913311457021828\n",
            "Recall: 0.9896394447602\n",
            "F1 Score: 0.99048457289536\n",
            "AUC-ROC: 0.9917003981640335\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[975021   6121]\n",
            " [  7328 699970]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define hyperparameters for DecisionTree\n",
        "dt_hyperparameters = [{'max_depth': None}, {'max_depth': 10}, {'max_depth': 20}, {'max_depth': 30}]\n",
        "\n",
        "# Train and evaluate DecisionTree with specified hyperparameters\n",
        "for params in dt_hyperparameters:\n",
        "    print(f\"\\nTraining DecisionTree with params: {params}...\")\n",
        "    model = DecisionTreeClassifier(**params, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating DecisionTree with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYPY_Z7Fk8AG"
      },
      "source": [
        "Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGbQzjCPlAKp",
        "outputId": "e92722f7-5d37-4cb2-d538-20856da4aa7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training RandomForest with params: {'n_estimators': 50, 'max_depth': None}...\n",
            "\n",
            "Evaluating RandomForest with params: {'n_estimators': 50, 'max_depth': None}...\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Training Time: 655.3493640422821\n",
            "Accuracy: 0.9915087299519083\n",
            "Precision: 0.9898628730908058\n",
            "Recall: 0.9898670715879304\n",
            "F1 Score: 0.9898649723349161\n",
            "AUC-ROC: 0.9912796304469309\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[973972   7170]\n",
            " [  7167 700131]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training RandomForest with params: {'n_estimators': 100, 'max_depth': 10}...\n",
            "\n",
            "Evaluating RandomForest with params: {'n_estimators': 100, 'max_depth': 10}...\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Training Time: 837.954954624176\n",
            "Accuracy: 0.9113489374807514\n",
            "Precision: 0.8792160735124901\n",
            "Recall: 0.9139273686621481\n",
            "F1 Score: 0.8962357540969969\n",
            "AUC-ROC: 0.9117087671019676\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92    981142\n",
            "           1       0.88      0.91      0.90    707298\n",
            "\n",
            "    accuracy                           0.91   1688440\n",
            "   macro avg       0.91      0.91      0.91   1688440\n",
            "weighted avg       0.91      0.91      0.91   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[892339  88803]\n",
            " [ 60879 646419]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training RandomForest with params: {'n_estimators': 200, 'max_depth': 20}...\n",
            "\n",
            "Evaluating RandomForest with params: {'n_estimators': 200, 'max_depth': 20}...\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Training Time: 2416.578173160553\n",
            "Accuracy: 0.9918042690293999\n",
            "Precision: 0.9855686417298024\n",
            "Recall: 0.9950049342709862\n",
            "F1 Score: 0.9902643087504432\n",
            "AUC-ROC: 0.9922509337183119\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99    981142\n",
            "           1       0.99      1.00      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[970837  10305]\n",
            " [  3533 703765]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define hyperparameters for RandomForest\n",
        "rf_hyperparameters = [\n",
        "    {'n_estimators': 50, 'max_depth': None},\n",
        "    {'n_estimators': 100, 'max_depth': 10},\n",
        "    {'n_estimators': 200, 'max_depth': 20}\n",
        "]\n",
        "\n",
        "# Train and evaluate RandomForest with specified hyperparameters\n",
        "for params in rf_hyperparameters:\n",
        "    print(f\"\\nTraining RandomForest with params: {params}...\")\n",
        "    model = RandomForestClassifier(**params, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating RandomForest with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ9ariHJlCB9"
      },
      "source": [
        "XGBoost classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuATJZavlFXv",
        "outputId": "c2dcf0de-4291-4b1c-e051-74253a153d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBoost with params: {'n_estimators': 50, 'max_depth': 3}...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:16:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating XGBoost with params: {'n_estimators': 50, 'max_depth': 3}...\n",
            "\n",
            "Model: XGBClassifier\n",
            "Training Time: 16.986750602722168\n",
            "Accuracy: 0.8988936533131174\n",
            "Precision: 0.8640813457383866\n",
            "Recall: 0.9002499653611349\n",
            "F1 Score: 0.8817949289642307\n",
            "AUC-ROC: 0.8990829316828525\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.91    981142\n",
            "           1       0.86      0.90      0.88    707298\n",
            "\n",
            "    accuracy                           0.90   1688440\n",
            "   macro avg       0.89      0.90      0.90   1688440\n",
            "weighted avg       0.90      0.90      0.90   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[880983 100159]\n",
            " [ 70553 636745]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training XGBoost with params: {'n_estimators': 100, 'max_depth': 6}...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:18:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating XGBoost with params: {'n_estimators': 100, 'max_depth': 6}...\n",
            "\n",
            "Model: XGBClassifier\n",
            "Training Time: 41.36726689338684\n",
            "Accuracy: 0.9355979484020753\n",
            "Precision: 0.9080028847084549\n",
            "Recall: 0.9416695650206843\n",
            "F1 Score: 0.9245298340321247\n",
            "AUC-ROC: 0.9364452649889231\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94    981142\n",
            "           1       0.91      0.94      0.92    707298\n",
            "\n",
            "    accuracy                           0.94   1688440\n",
            "   macro avg       0.93      0.94      0.93   1688440\n",
            "weighted avg       0.94      0.94      0.94   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[913660  67482]\n",
            " [ 41257 666041]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "\n",
            "Training XGBoost with params: {'n_estimators': 200, 'max_depth': 10}...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:22:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating XGBoost with params: {'n_estimators': 200, 'max_depth': 10}...\n",
            "\n",
            "Model: XGBClassifier\n",
            "Training Time: 112.96780729293823\n",
            "Accuracy: 0.9931202767051243\n",
            "Precision: 0.9913896862709642\n",
            "Recall: 0.9921942377894466\n",
            "F1 Score: 0.991791798865154\n",
            "AUC-ROC: 0.9929910445446292\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[975047   6095]\n",
            " [  5521 701777]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Define hyperparameters for XGBoost\n",
        "xgb_hyperparameters = [\n",
        "    {'n_estimators': 50, 'max_depth': 3},\n",
        "    {'n_estimators': 100, 'max_depth': 6},\n",
        "    {'n_estimators': 200, 'max_depth': 10}\n",
        "]\n",
        "\n",
        "# Train and evaluate XGBoost with specified hyperparameters\n",
        "for params in xgb_hyperparameters:\n",
        "    print(f\"\\nTraining XGBoost with params: {params}...\")\n",
        "    model = xgb.XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating XGBoost with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7YicdeslHe-"
      },
      "source": [
        "Gradient boosting classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlCfpo0TlMHs",
        "outputId": "57f0b5c6-4034-48b0-8610-dc29ba910546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training GradientBoosting with params: {'n_estimators': 50, 'max_depth': 6}...\n",
            "\n",
            "Evaluating GradientBoosting with params: {'n_estimators': 50, 'max_depth': 6}...\n",
            "\n",
            "Model: GradientBoostingClassifier\n",
            "Training Time: 1169.729799747467\n",
            "Accuracy: 0.9064041363625596\n",
            "Precision: 0.871594862170818\n",
            "Recall: 0.9107434207363798\n",
            "F1 Score: 0.8907391979203036\n",
            "AUC-ROC: 0.9070096995685301\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92    981142\n",
            "           1       0.87      0.91      0.89    707298\n",
            "\n",
            "    accuracy                           0.91   1688440\n",
            "   macro avg       0.90      0.91      0.90   1688440\n",
            "weighted avg       0.91      0.91      0.91   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[886242  94900]\n",
            " [ 63131 644167]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define hyperparameters for GradientBoosting\n",
        "gb_hyperparameters = [\n",
        "    {'n_estimators': 50, 'max_depth': 3},\n",
        "    {'n_estimators': 100, 'max_depth': 6},\n",
        "    {'n_estimators': 50, 'max_depth': 6}\n",
        "]\n",
        "\n",
        "# Train and evaluate GradientBoosting with specified hyperparameters\n",
        "for params in gb_hyperparameters:\n",
        "    print(f\"\\nTraining GradientBoosting with params: {params}...\")\n",
        "    model = GradientBoostingClassifier(**params, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating GradientBoosting with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTNfUlOlNwo"
      },
      "source": [
        "Gausian naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoLU1pNKlSNx",
        "outputId": "f10cc604-0813-4268-f5bc-ad0adfe53a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training GaussianNB with params: {}...\n",
            "\n",
            "Evaluating GaussianNB with params: {}...\n",
            "\n",
            "Model: GaussianNB\n",
            "Training Time: 3.0318479537963867\n",
            "Accuracy: 0.625537182251072\n",
            "Precision: 0.9038490517297053\n",
            "Recall: 0.11872364972048556\n",
            "F1 Score: 0.20987898085988074\n",
            "AUC-ROC: 0.5548094766782264\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.99      0.75    981142\n",
            "           1       0.90      0.12      0.21    707298\n",
            "\n",
            "    accuracy                           0.63   1688440\n",
            "   macro avg       0.76      0.55      0.48   1688440\n",
            "weighted avg       0.73      0.63      0.53   1688440\n",
            "\n",
            "Confusion Matrix:\n",
            " [[972209   8933]\n",
            " [623325  83973]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382             ham  \n",
            "2402104             ham  \n",
            "2319806             ham  \n",
            "325958             spam  \n",
            "1688799             ham  \n",
            "4606717             ham  \n",
            "5137027             ham  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Define hyperparameters for GaussianNB (empty as it has no hyperparameters)\n",
        "gnb_hyperparameters = [{}]\n",
        "\n",
        "# Train and evaluate GaussianNB with specified hyperparameters\n",
        "for params in gnb_hyperparameters:\n",
        "    print(f\"\\nTraining GaussianNB with params: {params}...\")\n",
        "    model = GaussianNB()\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating GaussianNB with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNYAIVL8R4Nn"
      },
      "source": [
        "adaboost graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "DAO9tRIMR6wa",
        "outputId": "2b0b9a1b-8457-40e3-cca0-659145947a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimators\tAccuracy\n",
            "----------------------------\n",
            "50\t\t0.8900\n",
            "100\t\t0.8930\n",
            "150\t\t0.8940\n",
            "200\t\t0.8947\n",
            "250\t\t0.8948\n",
            "300\t\t0.8949\n",
            "350\t\t0.8953\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c98b32f79510>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_estimators_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \"\"\"\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    441\u001b[0m             )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Range of n_estimators to try\n",
        "n_estimators_range = range(50, 500, 50)  # From 50 to 640 in steps of 20\n",
        "\n",
        "# Print header for the table\n",
        "print(\"n_estimators\\tAccuracy\")\n",
        "print(\"----------------------------\")\n",
        "\n",
        "# List to store accuracies\n",
        "accuracies = []\n",
        "\n",
        "for n in n_estimators_range:\n",
        "    model = AdaBoostClassifier(n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Print the n_estimators and corresponding accuracy\n",
        "    print(f\"{n}\\t\\t{accuracy:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(n_estimators_range, accuracies, marker='o')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Number of Estimators (AdaBoost)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY-CRz86bC0A"
      },
      "source": [
        "xgboost accuracy vs n estimators\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8WrvmhXMbNPK",
        "outputId": "2109d0a3-20c4-455c-a9b7-13c670aec495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimators\tAccuracy\n",
            "----------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:02:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\t\t0.9174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:02:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\t\t0.9247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:03:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90\t\t0.9316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:04:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110\t\t0.9394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:05:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130\t\t0.9467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:06:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\t\t0.9522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:07:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170\t\t0.9584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:08:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "190\t\t0.9631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:09:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "210\t\t0.9684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:11:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "230\t\t0.9726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:12:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250\t\t0.9758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:14:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "270\t\t0.9784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:16:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "290\t\t0.9811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:18:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "310\t\t0.9833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:20:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "330\t\t0.9851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:22:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "350\t\t0.9864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:24:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "370\t\t0.9879\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390\t\t0.9888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:29:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "410\t\t0.9898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:32:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "430\t\t0.9904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "450\t\t0.9911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:38:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "470\t\t0.9917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:41:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "490\t\t0.9919\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHWCAYAAACVPVriAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBEUlEQVR4nO3deVhU1f8H8PcM27AjsgmiLC6EC7giLdqioqihuaWZimXlkhqVXzFTscylNM1MbXEJ18yl7Fco4pZp4K5I4oaiyI4sgsAwc35/EJMji+wDM+/X88yDc+65937uPXfww51zz5EIIQSIiIiIiLSUVNMBEBERERHVJSa8RERERKTVmPASERERkVZjwktEREREWo0JLxERERFpNSa8RERERKTVmPASERERkVZjwktEREREWo0JLxERERFpNSa8REQ1cOTIEUgkEvz888+aDqVSkpOTMWzYMDRt2hQSiQQrVqzQaDwbN26ERCLBrVu3NBpHQ/PgwQPY2dlhy5Ytmg6lUVi7di1atGiBgoICTYdCDRQTXqJHfPPNN5BIJPDx8dF0KPSIkqRIJpMhISGh1PLnn38e7du310Bkjc97772H/fv3Izg4GKGhoejXr1+5dSUSSbmvd955p0r7/eyzz7B3794aRl+7Tpw4gfnz5yMzM1PToZSycuVKmJub49VXXwUACCHw3HPPwdbWFunp6aXqv/POOzAwMMD58+fVyrOzs7Fw4UJ07doVlpaWMDIyQsuWLTFy5Ej83//9n1rdkj/eHn1ZW1ujR48eDSbxLu86Gj9+PAoLC7Fu3br6D4oaBX1NB0DUkGzZsgUuLi6IiorC9evX0apVK02HRI8oKCjA4sWLsWrVKk2H0mgdOnQIAQEB+OCDDypVv0+fPhg7dmyp8jZt2lRpv5999hmGDRuGwYMHq5W//vrrePXVV2FkZFSl7dWGEydOICQkBOPHj4eVlVW97788crkcK1euxHvvvQc9PT0AxX98rFu3Dt7e3vjggw+wYcMGVf2TJ0/i22+/RVBQELy9vVXl169fh5+fH27fvo0hQ4Zg7NixMDMzw507d/D7779j4MCB+PHHH/H666+r7X/atGno1q0bACA9PR07duzAmDFjkJmZiSlTptT9CahAedeRTCbDuHHjsHz5crz77ruQSCSaCZAaLCa8RP+Ki4vDiRMnsHv3brz99tvYsmUL5s2bp+mwypSbmwtTU1NNh1HvvL298d133yE4OBiOjo6aDqde1Vabp6SkVCm5a9OmDcaMGVPj/ZZHT09PldRpAyEE8vPzYWxsXO1t/Pbbb0hNTcWIESPUyj09PfHhhx/is88+w/jx49GrVy/I5XK89dZbcHZ2RkhIiKpuUVERhgwZguTkZBw9ehTPPPOM2rbmzZuHAwcOQKFQlNr/c889h2HDhqneT5o0CW5ubti6davGE96KjBgxAkuXLsXhw4fx4osvajocamDYpYHoX1u2bEGTJk0wYMAADBs2rNyv8DIzM/Hee+/BxcUFRkZGaN68OcaOHYu0tDRVnfz8fMyfPx9t2rSBTCZDs2bN8Morr+DGjRsA/vvq8MiRI2rbvnXrFiQSCTZu3KgqGz9+PMzMzHDjxg34+/vD3Nwcr732GgDgzz//xPDhw9GiRQsYGRnB2dkZ7733Hh4+fFgq7itXrmDEiBGwtbWFsbEx2rZti48++ggAcPjwYUgkEuzZs6fUelu3boVEIsHJkyfLPB+nT5+GRCLBpk2bSi3bv38/JBIJfvvtNwBATk4OZsyYoTp3dnZ26NOnD86ePVvmth83e/ZsKBQKLF68uMJ6ZZ3HEhKJBPPnz1e9nz9/PiQSCa5evYoxY8bA0tIStra2+PjjjyGEwJ07dxAQEAALCws4ODhg2bJlZe5ToVBg9uzZcHBwgKmpKV5++WXcuXOnVL3IyEj069cPlpaWMDExQa9evfDXX3+p1SmJKSYmBqNHj0aTJk3w7LPPVnjMN2/exPDhw2FtbQ0TExP06NFD7Svrkm4hQgisXr1a9ZV1bbh27RqGDh0KBwcHyGQyNG/eHK+++iqysrIAFJ/z3NxcbNq0SbXf8ePHq8X1aB9eFxcXDBw4EEeOHEHXrl1hbGyMDh06qD4vu3fvRocOHSCTydClSxecO3dOLZ6LFy9i/PjxcHNzg0wmg4ODAyZMmKDWFWD+/Pn48MMPAQCurq6quEriKCoqwieffAJ3d3cYGRnBxcUFs2fPLtVHtCTW/fv3q2It+Vo9PDwczz77LKysrGBmZoa2bdti9uzZTzyfe/fuhYuLC9zd3Ust+/jjj+Hu7o63334bhYWFWLZsGaKjo/H111+r/UG0c+dOREdH4+OPPy6V7Jbo27cv+vfv/8R4DA0N0aRJE+jrq98jq+w5Aoq7i7Vr1w5GRkZwdHTElClTSnUlqcl1BABdunSBtbU1fvnllyceE+ke3uEl+teWLVvwyiuvwNDQEKNGjcKaNWtw6tQp1Vd7QPGDJM899xz++ecfTJgwAZ07d0ZaWhp+/fVX3L17FzY2NlAoFBg4cCAiIiLw6quvYvr06cjJyUF4eDiio6PL/E/sSYqKiuDn54dnn30WX3zxBUxMTAAU/6eWl5eHSZMmoWnTpoiKisKqVatw9+5d7Ny5U7X+xYsX8dxzz8HAwABvvfUWXFxccOPGDezbtw8LFy7E888/D2dnZ2zZsgVDhgwpdV7c3d3h6+tbZmxdu3aFm5sbfvrpJ4wbN05t2Y4dO9CkSRP4+fkBKO5n+PPPP2Pq1Knw9PREeno6jh8/jn/++QedO3d+4nlwdXXF2LFj8d1332HWrFm1epd35MiReOqpp7B48WL83//9Hz799FNYW1tj3bp1ePHFF7FkyRJs2bIFH3zwAbp164aePXuqrb9w4UJIJBL873//Q0pKClasWIHevXvj/Pnzqrt9hw4dQv/+/dGlSxfMmzcPUqkUGzZswIsvvog///wT3bt3V9vm8OHD0bp1a3z22WcQQpQbe3JyMp5++mnk5eVh2rRpaNq0KTZt2oSXX34ZP//8M4YMGYKePXsiNDQUr7/+erndFMqSn5+v9sdcCQsLCxgaGqKwsBB+fn4oKCjAu+++CwcHByQkJOC3335DZmYmLC0tERoaijfffBPdu3fHW2+9BQBP/Bxcv34do0ePxttvv40xY8bgiy++wKBBg7B27VrMnj0bkydPBgAsWrQII0aMQGxsLKTS4ns44eHhuHnzJgIDA+Hg4IDLly/j22+/xeXLl/H3339DIpHglVdewdWrV7Ft2zZ8+eWXsLGxAQDY2toCAN58801s2rQJw4YNw/vvv4/IyEgsWrQI//zzT6k/DGNjYzFq1Ci8/fbbmDhxItq2bYvLly9j4MCB6NixIxYsWAAjIyNcv3691B83ZTlx4kS5nweZTIZvvvkGfn5+mDx5MrZu3YohQ4Zg0KBBavX27dsHANW6O5+Tk6Nq84yMDGzduhXR0dH44Ycf1OpV9hzNnz8fISEh6N27NyZNmoTY2FjV79e//voLBgYGtXYdde7cuVLnmHSQICJx+vRpAUCEh4cLIYRQKpWiefPmYvr06Wr15s6dKwCI3bt3l9qGUqkUQgixfv16AUAsX7683DqHDx8WAMThw4fVlsfFxQkAYsOGDaqycePGCQBi1qxZpbaXl5dXqmzRokVCIpGI27dvq8p69uwpzM3N1coejUcIIYKDg4WRkZHIzMxUlaWkpAh9fX0xb968Uvt5VHBwsDAwMBAZGRmqsoKCAmFlZSUmTJigKrO0tBRTpkypcFtl2bBhgwAgTp06JW7cuCH09fXFtGnTVMt79eol2rVrp3pf1nksAUDteObNmycAiLfeektVVlRUJJo3by4kEolYvHixqvz+/fvC2NhYjBs3TlVW0pZOTk4iOztbVf7TTz8JAGLlypVCiOJz3bp1a+Hn56d23vPy8oSrq6vo06dPqZhGjRpVqfMzY8YMAUD8+eefqrKcnBzh6uoqXFxchEKhUDv+yrYBgHJf27ZtE0IIce7cOQFA7Ny5s8JtmZqaqp23EiVtGxcXpypr2bKlACBOnDihKtu/f78AIIyNjdWu43Xr1pX6LJX1udi2bZsAII4dO6Yq+/zzz0vtWwghzp8/LwCIN998U638gw8+EADEoUOHSsUaFhamVvfLL78UAERqamqZ56M8crlcSCQS8f7771dYb9SoUQKAMDc3F3fu3Cm1vFOnTsLKyqpU+YMHD0RqaqrqlZWVpVpWci0//pJKpWLhwoVq26nsOUpJSRGGhoaib9++atfh119/LQCI9evXCyFqfh2VeOutt4SxsXGF2yDdxC4NRCi+i2lvb48XXngBQPFXZyNHjsT27dvV+rjt2rULXl5epe6ClqxTUsfGxgbvvvtuuXWqY9KkSaXKHu0nmJubi7S0NDz99NMQQqi+5k1NTcWxY8cwYcIEtGjRotx4xo4di4KCArXhtXbs2IGioqIn3iUaOXIk5HI5du/erSo7cOAAMjMzMXLkSFWZlZUVIiMjce/evUoedWlubm54/fXX8e233yIxMbHa23ncm2++qfq3np4eunbtCiEE3njjDVW5lZUV2rZti5s3b5Zaf+zYsTA3N1e9HzZsGJo1a4bff/8dAHD+/Hlcu3YNo0ePRnp6OtLS0pCWlobc3Fy89NJLOHbsGJRKpdo2KzsSwu+//47u3burdXswMzPDW2+9hVu3biEmJqZyJ6EMAQEBCA8PL/Uq+axYWloCKO6+kpeXV+39PM7T01PtW4WSkVNefPFFteu4pPzRNnn0c1Fyh7pHjx4AUKnuMyVtFhQUpFb+/vvvA0Cp0Q1cXV1V32KUKOkn/csvv5Rq14pkZGRACIEmTZpUWK/kjrSnpyeaN29eanl2djbMzMxKlX/00UewtbVVvUaPHl2qzty5c1XtvGPHDowaNQofffQRVq5cqapT2XN08OBBFBYWYsaMGao78AAwceJEWFhYqOrV1nXUpEkTPHz4sFavRdIOTHhJ5ykUCmzfvh0vvPAC4uLicP36dVy/fh0+Pj5ITk5GRESEqu6NGzeeOPzVjRs30LZt21L93WpCX1+/zP/U4uPjMX78eFhbW8PMzAy2trbo1asXAKj6vZUkAk+K28PDA926dVPru7xlyxb06NHjiaNVeHl5wcPDAzt27FCV7dixAzY2NmoPjyxduhTR0dFwdnZG9+7dMX/+/DKTxyeZM2cOioqKntiXtyoe/2PA0tISMplMlVg8Wn7//v1S67du3VrtvUQiQatWrVR9Qq9duwYAGDdunFrCYWtri++//x4FBQWqNivh6upaqdhv376Ntm3blip/6qmnVMurq3nz5ujdu3epl729vSrGoKAgfP/997CxsYGfnx9Wr15d6liqqqz2AABnZ+cyyx9tk4yMDEyfPh329vYwNjaGra2t6lxWJq7bt29DKpWWuu4dHBxgZWVV6nyW1U4jR47EM888gzfffBP29vZ49dVX8dNPP1U6+RUVdGE5ffo0Vq9ejfbt2yMyMhKbN28uVcfc3BwPHjwoVT558mRVMlvSho/r0KGDqp1HjBiBzZs3Y+DAgZg1axZSU1MBVP4clfx8/Po0NDSEm5ubanltXUcl542jNNDjmPCSzjt06BASExOxfft2tG7dWvUqeUK6LsafLO+XcVlPTAOAkZGR2t2Rkrp9+vTB//3f/+F///sf9u7di/DwcNWDWlW5q1Ri7NixOHr0KO7evYsbN27g77//rnQfwJEjR+Lw4cNIS0tDQUEBfv31VwwdOlQt8R8xYgRu3ryJVatWwdHREZ9//jnatWuHP/74o0pxurm5YcyYMeXe5a3q+QVQ5kgB5Y0eUFEyUp6S9vj888/LvGMaHh5e6o5cTZ70r0/Lli3DxYsXMXv2bDx8+BDTpk1Du3btcPfu3Wpvs7xzX5k2GTFiBL777ju888472L17Nw4cOICwsDAAVftcVDZpKqudjI2NcezYMRw8eBCvv/46Ll68iJEjR6JPnz4VXofW1taQSCRl/lEFFF/Db731FhwdHfHXX3/Bx8cH77//fqkHwDw8PJCZmVlq3Oo2bdqoklmZTFap4wOAl156Cfn5+YiKilIrr83Esjauo/v378PExKTRfHao/jDhJZ23ZcsW2NnZYefOnaVeo0aNwp49e1SjHri7uyM6OrrC7bm7uyM2NhZyubzcOiVfVz7+n1RV7sRdunQJV69exbJly/C///0PAQEB6N27d6kHudzc3ADgiXEDwKuvvgo9PT1s27YNW7ZsgYGBgVqXhIqMHDkSRUVF2LVrF/744w9kZ2erBs1/VLNmzTB58mTs3bsXcXFxaNq0KRYuXFipfTyq5C7vkiVLSi2rjfNbVSV3cEsIIXD9+nW4uLgA+O/hGgsLizLvmPbu3RsGBgbV2nfLli0RGxtbqvzKlSuq5XWtQ4cOmDNnDo4dO4Y///wTCQkJWLt2rWp5fd1xu3//PiIiIjBr1iyEhIRgyJAh6NOnj+pz8KjyYmrZsiWUSmWpNk1OTkZmZmalz6dUKsVLL72E5cuXIyYmBgsXLsShQ4dw+PDhctfR19eHu7s74uLiylz+1Vdf4dy5c1i1ahUsLCywdu1apKenY9asWWr1Bg4cCKD2/mAvKioCANVd48qeo5Kfj1+fhYWFiIuLK3Uua3odxcXFqb7ZIHoUE17SaQ8fPsTu3bsxcOBADBs2rNRr6tSpyMnJwa+//goAGDp0KC5cuFDm8F0ld5iGDh2KtLQ0fP311+XWadmyJfT09HDs2DG15d98802lYy+50/XonS0hhFo/O6D4qfOePXti/fr1iI+PLzOeEjY2Nujfvz82b96MLVu2oF+/fqW+0i/PU089hQ4dOmDHjh3YsWMHmjVrpjaSgUKhKPX1pJ2dHRwdHas1Hai7uzvGjBmDdevWISkpSW2ZhYUFbGxsanR+q+rHH39ETk6O6v3PP/+MxMRE1bBPXbp0gbu7O7744osyv2ou+aq4Ovz9/REVFaU2dFxubi6+/fZbuLi4wNPTs9rbfpLs7GxVMlSiQ4cOkEqlau1qampaLzOalfW5AFDmFMolw3g9Hpe/v3+Z6yxfvhwAMGDAgCfGkZGRUaqsZFKIJ13vvr6+OH36dKnyO3fuYO7cuXj55ZdVEy94e3tj2rRp+O677xAZGamqO2LECHh6euKTTz7B33//XeZ+qvJNRcnQgl5eXgAqf4569+4NQ0NDfPXVV2r7++GHH5CVlaWqV1vX0dmzZ/H0009X+rhId3BYMtJpv/76K3JycvDyyy+XubxHjx6wtbXFli1bMHLkSHz44Yf4+eefMXz4cEyYMAFdunRBRkYGfv31V6xduxZeXl4YO3YsfvzxRwQFBSEqKgrPPfcccnNzcfDgQUyePBkBAQGwtLTE8OHDsWrVKkgkEri7u+O3335DSkpKpWP38PCAu7s7PvjgAyQkJMDCwgK7du0q86vQr776Cs8++yw6d+6Mt956C66urrh16xb+7//+r9RUpGPHjlUNOv/JJ59U/mSi+C7v3LlzIZPJ8MYbb6h1w8jJyUHz5s0xbNgweHl5wczMDAcPHsSpU6fKHdv2ST766COEhoYiNjYW7dq1U1v25ptvYvHixXjzzTfRtWtXHDt2DFevXq3WfirD2toazz77LAIDA5GcnIwVK1agVatWmDhxIoDiu33ff/89+vfvj3bt2iEwMBBOTk5ISEjA4cOHYWFhoRpKqqpmzZqFbdu2oX///pg2bRqsra2xadMmxMXFYdeuXaW6w1TF1atXy+wjam9vjz59+uDQoUOYOnUqhg8fjjZt2qCoqAihoaHQ09PD0KFDVfW7dOmCgwcPYvny5XB0dISrq2udTOFtYWGBnj17YunSpZDL5XBycsKBAwfKvGPapUsXAMXX0auvvgoDAwMMGjQIXl5eGDduHL799ltkZmaiV69eiIqKwqZNmzB48GDVA3sVWbBgAY4dO4YBAwagZcuWSElJwTfffIPmzZs/cUzlgIAAhIaG4urVq2oz2r377rsQQpSaaTAkJAQ//fQT3nnnHZw+fRp6enowMDDAnj17VMMZvvLKK3juuedgamqKhIQE/Prrr4iPjy8zef/zzz+Rn58PAKrfb0ePHsWrr74KDw8PAKj0ObK1tUVwcDBCQkLQr18/vPzyy4iNjcU333yDbt26qbpM1cZ1dObMGWRkZCAgIOCJ7UM6qN7HhSBqQAYNGiRkMpnIzc0tt8748eOFgYGBSEtLE0IIkZ6eLqZOnSqcnJyEoaGhaN68uRg3bpxquRDFwyJ99NFHwtXVVRgYGAgHBwcxbNgwcePGDVWd1NRUMXToUGFiYiKaNGki3n77bREdHV3msGSmpqZlxhYTEyN69+4tzMzMhI2NjZg4caK4cOFCmUNyRUdHiyFDhggrKyshk8lE27Ztxccff1xqmwUFBaJJkybC0tJSPHz4sDKnUeXatWuqoYyOHz9earsffvih8PLyEubm5sLU1FR4eXmJb7755onbfXRYsseVDNv26LBkQhS3wRtvvCEsLS2Fubm5GDFihEhJSSl3WLLHh48q77w/PgRayVBO27ZtE8HBwcLOzk4YGxuLAQMGlBoGToji4ZdeeeUV0bRpU2FkZCRatmwpRowYISIiIp4YU0Vu3Lghhg0bpmrf7t27i99++61UPdTSsGS9evUSQghx8+ZNMWHCBOHu7i5kMpmwtrYWL7zwgjh48KDatq5cuSJ69uwpjI2NBQDV0FLlDUs2YMCASsVeMgTd559/riq7e/eu6lq3tLQUw4cPF/fu3SvV9kII8cknnwgnJychlUrV4pDL5SIkJET1GXZ2dhbBwcEiPz9fbf3yYo2IiBABAQHC0dFRGBoaCkdHRzFq1Chx9erVik65EKL4s2JjYyM++eQTVdmePXsEAPHFF1+Uuc7PP/9c5nCImZmZYsGCBaJTp07CzMxMGBoaCmdnZzFs2DCxb98+tbplDUtmaGgoPDw8xMKFC0VhYaFa/cqeIyGKhyHz8PAQBgYGwt7eXkyaNEncv39ftbym15EQQvzvf/8TLVq0UBv2j6iERIhqPH1BRFqrqKgIjo6OGDRoUKmB5omofnzyySfYsGEDrl27plVTL9eVgoICuLi4YNasWZg+fbqmw6EGiH14iUjN3r17kZqaWumZuIio9r333nt48OABtm/frulQGoUNGzbAwMCg0mNXk+7hHV4iAgBERkbi4sWL+OSTT2BjY1OpAfqJiIgaA97hJSIAwJo1azBp0iTY2dnhxx9/1HQ4REREtYZ3eImIiIhIq/EOLxERERFpNSa8RERERKTVOPFEGZRKJe7duwdzc/N6mw6TiIiIiCpPCIGcnBw4Ojo+cYIdJrxluHfvHpydnTUdBhERERE9wZ07d9C8efMK6zDhLYO5uTmA4hNoYWGh4Wi0n1wux4EDB9C3b18YGBhoOhyqZ2x/4jWg29j+uq0m7Z+dnQ1nZ2dV3lYRJrxlKOnGYGFhwYS3HsjlcpiYmMDCwoK/7HQQ2594Deg2tr9uq432r0z3Uz60RkRERERajQkvEREREWk1JrxEREREpNWY8BIRERGRVmPCS0RERERajQkvEREREWk1JrxEREREpNWY8BIRERGRVmPCS0RERERajTOtEREREVGNKJQCUXEZSMnJh525DN1draEnffIMaPWFCS8RERGRlqqPRDQsOhEh+2KQmJWvKmtmKcO8QZ7o175Zre6rupjwEhEREWmh+khEw6ITMWnzWYjHypOy8jFp81msGdO5QSS97MNLREREpGVKEtFHk13gv0Q0LDqxxvtQKAVC9sWUSnYBqMpC9sVAoSyrRv3iHV4iIiIiDair7gaVSUTn7I2GtakRFEqBgiIFCouUKChSqn6WLitdJzErv1RC/fi+ErPyERWXAV/3pjU+rppgwktERERUz2qzu0G+XIHErHzcy3yIhPsPERmXXmEiCgBpDwoxYt3JasVeVSk5FcdSH5jwEhEREdWjqvR7FUIgM0+OhMyHSMh8qEpq72UV/0zIzEfag4JqxWFtagBrUyMY6klhZCD996ee6r1RyU99PRjqS2GkL1Wrm5D5EN/9GffE/diZy6oVX21iwktERET0iLoc2aAy3Q2CfrqALZHxqru2eYWKJ27X2EAPTk2M4WhlDH2pBIeupDxxndWju9Soq4FCKfDbxUQkZeWXeTwSAA6WxedP05jwEhEREf2rtkc2EEIgI7cQ8Rl5iM/Iw1/X057Y3SCvUIE/r6WpldmYGcGpiTGcrGRwtDRWJbdO/76sTAwgkRQn5QqlwLNLDtV5IqonlWDeIE9M2nwWEkBtXyV/Hswb5NkgxuNlwktERESE6g+xlS9X4E5GHu7cz0N8eh7iMx7izv083Pk3ya3MHdrHjerujIEdHeFkZQwHSxlkBnqVXrc+E9F+7ZthzZjOpf5IcOA4vOpWr16Nzz//HElJSfDy8sKqVavQvXv3MuvK5XIsWrQImzZtQkJCAtq2bYslS5agX79+qjo5OTn4+OOPsWfPHqSkpKBTp05YuXIlunXrVl+HRERERHVA010NPtoTjez8Ity9/1CVzN7JyENKTsV9aCUSwMFCBmdrE8gMpDh2Na3C+gDwspdTjbob1Gci2q99M/TxdOBMa+XZsWMHgoKCsHbtWvj4+GDFihXw8/NDbGws7OzsStWfM2cONm/ejO+++w4eHh7Yv38/hgwZghMnTqBTp04AgDfffBPR0dEIDQ2Fo6MjNm/ejN69eyMmJgZOTk71fYhERERUC+pqEgUhBLLzi3DgctITuxqk5xZi5s8Xy1xmbqSPFk1N4NzEpPintQmcmxijhbUJnJoYw0i/+A5tfXU3AOo3EdWTSjQ+9FhFNJrwLl++HBMnTkRgYCAAYO3atfi///s/rF+/HrNmzSpVPzQ0FB999BH8/f0BAJMmTcLBgwexbNkybN68GQ8fPsSuXbvwyy+/oGfPngCA+fPnY9++fVizZg0+/fTT+js4IiIiqhXV7WqgUAqkPShAYlY+krLykZxdPG5scnbx+6R/fz6UV77LQVsHc3Ru0QQtrE1UL2drY1ga/9eHtiL13e+1oSei9UVjCW9hYSHOnDmD4OBgVZlUKkXv3r1x8mTZ48IVFBRAJlMf2sLY2BjHjx8HABQVFUGhUFRYp7ztFhT893VEdnY2gOIuFHK5vGoHRlVWco55rnUT2594Dei2J7W/Qikw/9fLFXY1mLXrEq4mZSP1QWFxMpudj+TsAqQ9KKz0LF+mhnrIrURf24/928KnjLuvRUVFldoPALzU1garXvXCp79fQVL2f/mHg6URPurvgZfa2ujM56Emn/+qrCMRQmhkvrd79+7ByckJJ06cgK+vr6p85syZOHr0KCIjI0utM3r0aFy4cAF79+6Fu7s7IiIiEBAQAIVCoUpYn376aRgaGmLr1q2wt7fHtm3bMG7cOLRq1QqxsbFlxjJ//nyEhISUKt+6dStMTExq6YiJiIioqv7JlGDtP5V/YOtxUghYGAKWhoCVoSjzp6UhoC8FQs7qIbMQ+O9e66MErAyBeZ0VqK0eAUoB3MiWIFsOWBgA7hai1ratC/Ly8jB69GhkZWXBwsKiwroaf2itKlauXImJEyfCw8MDEokE7u7uCAwMxPr161V1QkNDMWHCBDg5OUFPTw+dO3fGqFGjcObMmXK3GxwcjKCgINX77OxsODs7o2/fvk88gVRzcrkc4eHh6NOnDwwMDDQdDtUztj/xGtAOCqXA6dv3kZJTADtzI3Rt2aRSX8s/2v7ZhQL/JObgSlKO6ue11AeV2n/XFlbo0rIJHCyNYG8ug72FEewtjGBjZlTp7gEGLsl4d/sFAGV1NZDg01e84NfOvlLbosqpyee/5Bv5ytBYwmtjYwM9PT0kJyerlScnJ8PBwaHMdWxtbbF3717k5+cjPT0djo6OmDVrFtzc3FR13N3dcfToUeTm5iI7OxvNmjXDyJEj1eo8zsjICEZGRqXKDQwM+Mu3HvF86za2P/EaaLyq+kCZQilwKz0X/yRmI/puJo7+I8Vn0SeQ/ITRDiryvp9HjfuqDvRuDn19vQY/xJY2qs7nvyr1NZbwGhoaokuXLoiIiMDgwYMBAEqlEhEREZg6dWqF68pkMjg5OUEul2PXrl0YMWJEqTqmpqYwNTXF/fv3sX//fixdurQuDoOIiEinPemBshWvesPZ2gQx97IRk5iNfxKzcSUx57EHxaQAipNdVxtTPNXMHJ7NLODpaIE29uYYtvYkkutpNq/GMMQWVZ1GuzQEBQVh3Lhx6Nq1K7p3744VK1YgNzdXNWrD2LFj4eTkhEWLFgEAIiMjkZCQAG9vbyQkJGD+/PlQKpWYOXOmapv79++HEAJt27bF9evX8eGHH8LDw0O1TSIiIqodlRm7dvr282WuKzOQoq2DBTzszaBMv41hvX3RrnkTmBmVTk3m1/NsXhzZQPtoNOEdOXIkUlNTMXfuXCQlJcHb2xthYWGwty/uHxMfHw+pVKqqn5+fjzlz5uDmzZswMzODv78/QkNDYWVlpaqTlZWF4OBg3L17F9bW1hg6dCgWLlzIr8mIiEgn1fZkDXKFErfTc3E9JReHY1OeOHYtAFgaG8Db2QqejhZ4qpkFPJtZwNXGFHpSCeRyOX7//RY6t7CCgUHZaUljmc2LGi6NP7Q2derUcrswHDlyRO19r169EBMTU+H2RowYUWYXByIiIl1Tk8kacvLluJmai+spD3A99QFu/PszPj0PRZUc6qvEgoB2CPCu2eRP7GpANaHxhJeIiIhqX2Uma/Br54CUnAJVMvvfz1wkZZd/59bUUA/udmawkBng+PUnT5NrZy57Yp3KYFcDqi4mvERERFqmMn1r3912DkZ6UjyoYLIFW3MjuNuaopWdGVrZmsHdzgyt7MzgYCGDRCKp12lyiWqCCS8REZGWiYrLeGLfWrlCQK4onkShZVNTuNuawt3ODO62xUmtu40ZLE0qfv6lvqfJJaouJrxERERaoEihxIW7mTgam4o95xMqtU5wfw+Mf8YFRvrVn8mMD5RRY8CEl4iIqJFKyc7H0aupOHI1FcevpSHrobxK63dsblWjZLcEHyijho4JLxERkYZUdcgwuUKJs7fv48jVVByNTUVMovrUqpbGBniutQ16trHFF/tjkZpTUG99a/lAGTVkTHiJiIg0oLJDht3LfIij/ya4f11PQ05BkWqZRAJ0dLJEr7Z26NXGFt7OVqqE2UKmz761RP9iwktERFTPnjRk2PSXWiO3sAhHr6biavIDtTrWpobo2doGz7e1w3OtbdDUzKjMfbBvLdF/mPASERHVo8oMGbYi4pqqTCoBvJ2t8Py/d3E7OFlCWsk7s+xbS1SMCS8REVE9qsyQYQDQs40NhndxxnOtbWBlYljt/bFvLRETXiIiojolhMDNtFxExWUgKi4DR2JTKrXe0M7NMcjLsY6jI9INTHiJiIgeU9XREx5f95/EbJy6VZzgnrqVgbQHhVWOobam4yUiJrxERERqKjt6QonCIiUuJWQi8t87uGdu3VcbSQEAjPSl8Ha2go+rNbq0bIKZuy4iJbv+hgwj0nVMeImIiP71pNET1ozpjJ5tbHH2diai4tIRdSsD5+IzUVCkVKtvZqSPri5N0M3FGj6u1ujQ3FJtgoeQl9txyDCiesSEl4iICJUbPeHdbeegVAooHqvU1NQQ3Vys0d21+PVUM4sKE1YOGUZUv5jwEhERoXKjJ8j/zXSdrIzR3dValeS625pCIqnaHVkOGUZUf5jwEhGRzsuXK3A4NrlSdecN8kTgM661sl8OGUZUP5jwEhGRTsrJl+NwbCr2X07CkSspyC1UVGo9DweLOo6MiGobE14iItIZaQ8KEB6TjP2Xk3DiejoKFf89bGZvboScgiLklZP4cvQEosaLCS8RETUa1Rkf905GHvZfTsKBy8k4dTsD4pEHztxsTeHXzgF+7RzQ0ckSB2KSMGnzWQAcPYFImzDhJSKiRqGy4+MKIRCbnIP90cV3cmMSs9W208HJEn7t7NGvvQNa2ZmrLePoCUTaiQkvERE1eE8aH3f16M6wt5ThwOUkhF1Owu30PFUdqQTo7moNv3YO6NvOAU5WxhXui6MnEGkfJrxERNSgVWZ83KnbzkL5SAVDfSmea2UDv3YOeOkpOzQ1M6rSPjl6ApF2YcJLREQNWmXGx1UKQGYgRV/P4v64vdrawsyI/8URUTH+NiAiogYtJafiZLfEwsHtMbSLcx1HQ0SNERNeIiJqkJRKgePX07D579uVqu9oZVLHERFRY8WEl4iIGpSUnHzsPH0X20/F407GwyfW5/i4RPQkTHiJiEjjlAI4fj0dP51JQHhMMor+fQLNXKaPVzo5wbmpCRb+9g8Ajo9LRFXHhJeIiDQmJScfOyJvY+M5PaT/fUZV3rmFFUZ1b4GBHR1hbKgHAGhuZczxcYmoWpjwEhFRvVIqBf66kYZtUfE4cLnkbq4EZkb6eKWzE0Z1b4GnmlmUWo/j4xJRdTHhJSKiWvGkaX9Tcwqw88wdbI+6g/iM/yaG8Ha2xFOGGZg1+kVYmlY8KQTHxyWi6mDCS0RENVbetL8fD/CEhbEBtkbdfuRuLmBupI8h/97NbWVjjN9//x0mhvwviYjqBn+7EBFRjZQ37W9iVj4mbz2rVubtbIXRPi0wsGMzVYIrl8vrKVIi0lVMeImIqNoqmva3hATAaJ8WeM2nJTwdS/fNJSKqa1JNB0BERI1XZab9FQAGdnRksktEGsOEl4iIqu3kzfRK1avs9MBERHVB4wnv6tWr4eLiAplMBh8fH0RFRZVbVy6XY8GCBXB3d4dMJoOXlxfCwsLU6igUCnz88cdwdXWFsbEx3N3d8cknn0CIir5wIyKiqjgbfx+v/xCJryKuVaq+nbmsjiMiIiqfRvvw7tixA0FBQVi7di18fHywYsUK+Pn5ITY2FnZ2dqXqz5kzB5s3b8Z3330HDw8P7N+/H0OGDMGJEyfQqVMnAMCSJUuwZs0abNq0Ce3atcPp06cRGBgIS0tLTJs2rb4PkYhIq1y6m4Xl4bE4HJsKANCTAEYGesgrVJRZn9P+ElFDoNE7vMuXL8fEiRMRGBgIT09PrF27FiYmJli/fn2Z9UNDQzF79mz4+/vDzc0NkyZNgr+/P5YtW6aqc+LECQQEBGDAgAFwcXHBsGHD0Ldv3wrvHBMRUcX+SczGxB9PY9DXx3E4NhV6UglGdG2OIx++gOUjvCDBf9P8luC0v0TUUGjsDm9hYSHOnDmD4OBgVZlUKkXv3r1x8uTJMtcpKCiATKb+tZixsTGOHz+uev/000/j22+/xdWrV9GmTRtcuHABx48fx/Lly8uNpaCgAAUFBar32dnZAIq7UHC4nLpXco55rnUT279hu5byAKsO3cAfl5MBAFIJ8HLHZpj6gjtaNjUBADi0tcGqV73w6e9XkJT93+9SB0sjfNTfAy+1tamwfXkN6Da2v26rSftXZR2J0FDn1nv37sHJyQknTpyAr6+vqnzmzJk4evQoIiMjS60zevRoXLhwAXv37oW7uzsiIiIQEBAAhUKhSliVSiVmz56NpUuXQk9PDwqFAgsXLlRLrB83f/58hISElCrfunUrTExMauFoiYgal5SHQNhdKc6mSSAggQQC3k0F+jVXwqGcX4tKAdzIliBbDlgYAO4WAryxS0R1JS8vD6NHj0ZWVhYsLCoeBaZRjcO7cuVKTJw4ER4eHpBIJHB3d0dgYKBaF4iffvoJW7ZswdatW9GuXTucP38eM2bMgKOjI8aNG1fmdoODgxEUFKR6n52dDWdnZ/Tt2/eJJ5BqTi6XIzw8HH369IGBgYGmw6F6xvZvWOIz8rD6yE3svXAP/06Khr6edpj2gjvaOpjXyT55Deg2tr9uq0n7l3wjXxkaS3htbGygp6eH5ORktfLk5GQ4ODiUuY6trS327t2L/Px8pKenw9HREbNmzYKbm5uqzocffohZs2bh1VdfBQB06NABt2/fxqJFi8pNeI2MjGBkZFSq3MDAgB++esTzrdvY/pqVkPkQXx+6hp2n76qm/33Jww7v9WmD9k6W9RIDrwHdxvbXbdVp/6rU11jCa2hoiC5duiAiIgKDBw8GUNwdISIiAlOnTq1wXZlMBicnJ8jlcuzatQsjRoxQLcvLy4NUqv4snp6eHpRKZa0fAxFRY6BQCkTFZSAlJx925sUjJpQ8RJaUlY/Vh69j+6l4yBXFiW7PNrYI6tMG3s5WGoyaiKj2aLRLQ1BQEMaNG4euXbuie/fuWLFiBXJzcxEYGAgAGDt2LJycnLBo0SIAQGRkJBISEuDt7Y2EhATMnz8fSqUSM2fOVG1z0KBBWLhwIVq0aIF27drh3LlzWL58OSZMmKCRYyQi0qSw6ESE7ItRmw2tmaUMM3q3RmzSA2yOvI3CouIbAk+7N0VQnzbo6sIhxIhIu2g04R05ciRSU1Mxd+5cJCUlwdvbG2FhYbC3twcAxMfHq92tzc/Px5w5c3Dz5k2YmZnB398foaGhsLKyUtVZtWoVPv74Y0yePBkpKSlwdHTE22+/jblz59b34RERaVRYdCImbT6Lx59MTszKx/92XVK97+bSBEF92sLXvWn9BkhEVE80/tDa1KlTy+3CcOTIEbX3vXr1QkxMTIXbMzc3x4oVK7BixYpaipCIqPFRKAVC9sWUSnYfZaAnwfdju6JnG1tIJBxOgYi0l8anFiYiotoXFZeh1o2hLHKFgKG+HpNdItJ6THiJiLTQxbuZlaqXklNxUkxEpA003qWBiIhqz+lbGVh79AYO/pNSqfp25rInVyIiauSY8BIRNXJKpcChKylYe/QGTt++ryo30peioKjsIRklABwsi4coIyLSdkx4iYgaqcIiJX45n4Bvj93EtZQHAABDPSle6eyEiT3dcC05B5M2nwUAtYfXSnrszhvkqRqPl4hImzHhJSJqZB4UFGF7VDx+OB6nejDN3Egfr/VoiQnPuMDOoribgrutGdaM6VxqHF4HSxnmDfJEv/bNNBI/EVF9Y8JLRNRIpOYUYNOJW/jx5C1k5xcBAOzMjTDhWVeM9mkBC1npaTb7tW+GPp4O5c60RkSkC5jwEhE1cLfTc/HtsZv4+cxdVZ9cNxtTvNXTDUM6O8FIX6/C9fWkEk4qQUQ6jQkvEZEGKZSi3Luv0QlZWHP0Bv64lAjlv51wvZ2t8E4vd/T1tIeUd2mJiCqFCS8RkYaERSeW2b92RNfmOHs7E8evp6nKn29ri3d6ucPH1ZoTRRARVRETXiIiDQiLTsSkzWdLTf2blJWPryKuAyjuivCylyPe6umGp5pZ1H+QRERaggkvEVE9UygFQvbFlEp2H2ViqIc/pj+Hlk1N6y0uIiJtxamFiYjqWVRchlo3hrLkFSpwL5PT/hIR1QYmvERE9exSQlal6qXkMOElIqoN7NJARFRPsvPl+OrgNaz/K65S9e3MZXUcERGRbmDCS0RUx5RKgZ1n7uDz/bFIe1AIADDSl6rG1H2cBMWjNXR3ta7HKImItBcTXiKiOnTmdgbm/xqj6sbgZmuKuQM9kS9XYNLmswCg9vBayYBj8wZ5cjY0IqJawoSXiKgOJGXlY/Ef/2Dv+XsAAHMjfUzv3RpjfV1gqF/8+MSaMZ3LHId33iBP9GvfTCNxExFpIya8RES1KF+uwA/H47D68HXkFSogkQAjujjjA7+2sDU3Uqvbr30z9PF0KHemNSIiqh1MeImIaoEQAgf/ScEnv8UgPiMPANC5hRXmv9wOHZtblbuenlQCX/em9RQlEZFuYsJLRFRD11NyELIvBn9eK54K2M7cCMH+Hhjs7cRpgImIGgAmvERE1ZT1UI6VB6/hx5O3UKQUMNST4o3nXDHlhVYwM+KvVyKihoK/kYmIqkihFPjp9B18sT8W6bnFw4z1fsoecwY8BRcbTgVMRNTQMOElIiqDQinKfJjs9K0MzN93GdEJ2QAAd1tTzBvUDj3b2Go4YiIiKg8TXiKix4RFJ5YaLszO3Agtm5rg1K37AIqHGZvRpw3G+raEgR5naSciasiY8BIRPSIsOhGTNp9VmwwCAFJyCpCSUwAAeLVb8TBjNmZGpTdAREQNDhNeIqJ/KZQCIftiSiW7j7IxM8TCIR04Vi4RUSPC7+GIiP4VFZeh1o2hLGkPChEVl1FPERERUW1gwktE9K+UnIqT3arWIyKihoEJLxHRv1L/7aP7JHbmsjqOhIiIahP78BKRzhNCYO3Rm1gadqXCehIADpbFQ5QREVHjwTu8RKTTsvPleDv0DJaEXYEA0MO1KSQoTm4fVfJ+3iBPPrBGRNTI8A4vEemsK0nZmLT5LOLScmGoJ8X8l9thVHdn7L+cVGocXgdLGeYN8kS/9s00GDEREVUHE14i0kl7zt1F8O5LyJcr4WRljG9e6wwvZysAQL/2zdDH06HMmdaIiKjxYcJLRDqloEiBT3/7B6F/3wYA9Gxji5UjvdHE1FCtnp5UAl/3ppoIkYiIahkTXiLSGfcyH2LylrM4fycTADDtpdaY/lJr3rklItJyDeKhtdWrV8PFxQUymQw+Pj6Iiooqt65cLseCBQvg7u4OmUwGLy8vhIWFqdVxcXGBRCIp9ZoyZUpdHwoRNVDHr6Vh4KrjOH8nE5bGBtgwvhuC+rRhsktEpAM0nvDu2LEDQUFBmDdvHs6ePQsvLy/4+fkhJSWlzPpz5szBunXrsGrVKsTExOCdd97BkCFDcO7cOVWdU6dOITExUfUKDw8HAAwfPrxejomIGg6lUmD14esYuz4SGbmFaOdogd/efRYveNhpOjQiIqonGk94ly9fjokTJyIwMBCenp5Yu3YtTExMsH79+jLrh4aGYvbs2fD394ebmxsmTZoEf39/LFu2TFXH1tYWDg4Oqtdvv/0Gd3d39OrVq74Oi4gagKyHcrwVehqf74+FUgAjuzpj16Sn4WxtounQiIioHmm0D29hYSHOnDmD4OBgVZlUKkXv3r1x8uTJMtcpKCiATKY+y5GxsTGOHz9e7j42b96MoKAgSCRlf3VZUFCAgoL/ZljKzs4GUNx9Qi6XV+mYqOpKzjHPtW6qq/aPSczG1G0XcOf+QxjqSzF/oAeGd2kOQAm5XFmr+6Ka4e8A3cb21201af+qrKPRhDctLQ0KhQL29vZq5fb29rhypewZj/z8/LB8+XL07NkT7u7uiIiIwO7du6FQKMqsv3fvXmRmZmL8+PHlxrFo0SKEhISUKj9w4ABMTHgnqL6UdD0h3VSb7R+VIsFPN6WQCwmsjQQmtCmEafJF/P77xVrbB9U+/g7QbWx/3Vad9s/Ly6t03UY3SsPKlSsxceJEeHh4QCKRwN3dHYGBgeV2gfjhhx/Qv39/ODo6lrvN4OBgBAUFqd5nZ2fD2dkZffv2hYWFRa0fA6mTy+UIDw9Hnz59YGBgoOlwqJ7VZvsXFCnx6e9XsP3GXQBArzY2+GJoB1iZ8LpqyPg7QLex/XVbTdq/5Bv5ytBowmtjYwM9PT0kJyerlScnJ8PBwaHMdWxtbbF3717k5+cjPT0djo6OmDVrFtzc3ErVvX37Ng4ePIjdu3dXGIeRkRGMjIxKlRsYGPDDV494vnVbTdv/7v08TN5yFhfvZkEiAd7r3QZTX2gFKUdhaDT4O0C3sf11W3Xavyr1NfrQmqGhIbp06YKIiAhVmVKpREREBHx9fStcVyaTwcnJCUVFRdi1axcCAgJK1dmwYQPs7OwwYMCAWo+diDRDoRQ4eSMdv5xPwMkb6VAoBY5eTcXAVcdx8W4WrEwMsDGwO6a91JrJLhERAWgAXRqCgoIwbtw4dO3aFd27d8eKFSuQm5uLwMBAAMDYsWPh5OSERYsWAQAiIyORkJAAb29vJCQkYP78+VAqlZg5c6badpVKJTZs2IBx48ZBX1/jh0lEtSAsOhEh+2KQmJWvKjMz0seDgiIAQMfmlvjmtc5o3oR974mI6D8azwRHjhyJ1NRUzJ07F0lJSfD29kZYWJjqQbb4+HhIpf/diM7Pz8ecOXNw8+ZNmJmZwd/fH6GhobCyslLb7sGDBxEfH48JEybU5+EQUR0Ji07EpM1nIR4rL0l2n2ttg+/HdYWRvl79B0dERA2axhNeAJg6dSqmTp1a5rIjR46ove/VqxdiYmKeuM2+fftCiMf/aySixkihFAjZF1Mq2X3U9ZQH0JdqfGhxIiJqgPi/AxE1eFFxGWrdGMqSmJWPqLiMeoqIiIgaEya8RNTgpeRUnOxWtR4REekWJrxE1ODZmcueXKkK9YiISLc0iD68REQVySssqnC5BICDpQzdXa3rJyAiImpUeIeXiBq08JhkTNp8VvX+8ZF1S97PG+QJPY67S0REZWDCS0QN1u+XEjFp8xkUKpTw7+CAr0d3goOlercFB0sZ1ozpjH7tm2koSiIiaujYpYGIGqRfzifgvR3noRRAgLcjlg33gr6eFP3bN0NUXAZScvJhZ17cjYF3domIqCJMeImowfnp9B38b9dFCAEM69IcS4Z2VCW1elIJfN2bajhCIiJqTJjwElGDsiXyNj7aEw0AGO3TAp8GtIeUd3CJiKgGmPASUYOx8a84zN9XPJPi+KddMG+QJyQSJrtERFQzTHiJqEH4/vgtLNl/FQDwdk83zOrvwWSXiIhqBRNeItK4/Xcl+P1OcbL77outENSnDZNdIiKqNUx4iUhjhBD48uB1/H5HDwDwfp82ePel1hqOioiItA0TXiLSCCEEFv9xBeuO3QQAzPRrjckvMNklIqLax4SXiOqdEAIh+2Kw8cQtAMArLgpMfNZVs0EREZHWYsJLRPVKqRSY80s0tkbGAwAWvPwULFMvaTgqIiLSZpxamIjqjUIp8L9dF7E1Mh4SCbB0WEeM6uas6bCIiEjL8Q4vEdWLIoUSH+y8gL3n70EqAZaP8MbgTk6Qy+WaDo2IiLQcE14iqnNyhRIztp/H/11KhL5UgpWvdsKAjs00HRYREekIJrxEVKcKihSYuvUcwmOSYaAnwerRndG3nYOmwyIiIh3ChJeIao1CKRAVl4GUnHzYmcvQsbklpmw9iyOxqTDUl2Ld613wQls7TYdJREQ6hgkvEdWKsOhEhOyLQWJWvqrMUE+KQoUSMgMpvh/bDc+2ttFghEREpKuY8BJRjYVFJ2LS5rMQj5UXKpQAgMnPt2KyS0REGsNhyYioRhTK4kkkHk92H7UtKh4KZUU1iIiI6g4TXiKqkai4DLVuDGVJzMpHVFxGPUVERESkjgkvEdVISk7FyW5V6xEREdU2JrxEVCN25rJarUdERFTb+NAaEdVIcnbFd24lABwsZejual0/ARERET2GCS8RVYsQAt8cuYHP98eqyiSA2sNrkn9/zhvkCT2pBERERJrALg1EVGVyhRKzdl1SJbtvPOuKb0Z3hoOlercFB0sZ1ozpjH7tOY0wERFpDu/wElGVZOfLMXnzWRy/ngapBJj/cjuM9XUBAPi1d1Cbaa27qzXv7BIRkcYx4SWiSrt7Pw8TNp7C1eQHMDHUw6pRnfDSU/aq5XpSCXzdm2owQiIiotKY8BJRpVy8m4k3Np1Gak4B7MyNsH58N7R3stR0WERERE/EhJeInujA5SRM334eD+UKeDiYY/34bnC0MtZ0WERERJXChJeIKrT+eBw++b8YCAH0bGOL1aM7wVxmoOmwiIiIKo0JLxGVSaEU+OS3GGw8cQsAMKp7CywIaAcDPQ7uQkREjYvG/+davXo1XFxcIJPJ4OPjg6ioqHLryuVyLFiwAO7u7pDJZPDy8kJYWFipegkJCRgzZgyaNm0KY2NjdOjQAadPn67LwyDSKrkFRXg79LQq2Q3u74HPhrRnsktERI1Slf/3cnFxwYIFCxAfH1/jne/YsQNBQUGYN28ezp49Cy8vL/j5+SElJaXM+nPmzMG6deuwatUqxMTE4J133sGQIUNw7tw5VZ379+/jmWeegYGBAf744w/ExMRg2bJlaNKkSY3jJdIFydn5GPntSRz8JwWG+lKsHt0Zb/dyh0TC4cWIiKhxqnLCO2PGDOzevRtubm7o06cPtm/fjoKCgmrtfPny5Zg4cSICAwPh6emJtWvXwsTEBOvXry+zfmhoKGbPng1/f3+4ublh0qRJ8Pf3x7Jly1R1lixZAmdnZ2zYsAHdu3eHq6sr+vbtC3d392rFSKRLriRlY8jqvxCdkI2mpobYNrEHBnTkpBFERNS4VbkP74wZMzBjxgycPXsWGzduxLvvvovJkydj9OjRmDBhAjp37lyp7RQWFuLMmTMIDg5WlUmlUvTu3RsnT54sc52CggLIZOozORkbG+P48eOq97/++iv8/PwwfPhwHD16FE5OTpg8eTImTpxYbiwFBQVqSXt2djaA4i4Ucrm8UsdD1VdyjnmuNevP62l4d/sF5BYo4GZjgu9e74wW1iZ13i5sf+I1oNvY/rqtJu1flXUkQghR5T08trNvvvkG//vf/yCXy9GhQwdMmzYNgYGBFX4Feu/ePTg5OeHEiRPw9fVVlc+cORNHjx5FZGRkqXVGjx6NCxcuYO/evXB3d0dERAQCAgKgUChUCWtJQhwUFIThw4fj1KlTmD59OtauXYtx48aVGcv8+fMREhJSqnzr1q0wMTGp0vkgaoxOJEuw86YUSkjQykJgQhsFTDkQAxERNWB5eXkYPXo0srKyYGFhUWHdaie8crkce/bswYYNGxAeHo4ePXrgjTfewN27d7F69Wq8+OKL2Lp1a7nrVyfhTU1NxcSJE7Fv3z5IJBK4u7ujd+/eWL9+PR4+fAgAMDQ0RNeuXXHixAnVetOmTcOpU6cqvHP8+B1eZ2dnpKWlPfEEUs3J5XKEh4ejT58+MDBgllWflEqBZQev4ds/bwEABns1w6eD28FIv/4eTmP7E68B3cb21201af/s7GzY2NhUKuGtcpeGs2fPYsOGDdi2bRukUinGjh2LL7/8Eh4eHqo6Q4YMQbdu3Srcjo2NDfT09JCcnKxWnpycDAcHhzLXsbW1xd69e5Gfn4/09HQ4Ojpi1qxZcHNzU9Vp1qwZPD091dZ76qmnsGvXrnJjMTIygpGRUalyAwMDfvjqEc93/cqXK/D+rgv4v4uJAIDpL7XGjN6tNfZwGtufeA3oNra/bqtO+1elfpUT3m7duqFPnz5Ys2YNBg8eXObOXF1d8eqrr1a4HUNDQ3Tp0gUREREYPHgwAECpVCIiIgJTp06tcF2ZTAYnJyfI5XLs2rULI0aMUC175plnEBsbq1b/6tWraNmyZSWPkEj7KJQCUXEZSMnJh525DO62pnhn8xmcjc+EgZ4Ei1/piKFdmms6TCIiojpR5YT35s2bT0weTU1NsWHDhiduKygoCOPGjUPXrl3RvXt3rFixArm5uQgMDAQAjB07Fk5OTli0aBEAIDIyEgkJCfD29kZCQgLmz58PpVKJmTNnqrb53nvv4emnn8Znn32GESNGICoqCt9++y2+/fbbqh4qkVYIi05EyL4YJGblq8r0pBIolAIWMn2se70rfN2bajBCIiKiulXlhDclJQVJSUnw8fFRK4+MjISenh66du1a6W2NHDkSqampmDt3LpKSkuDt7Y2wsDDY29sDAOLj4yGV/teXMD8/H3PmzMHNmzdhZmYGf39/hIaGwsrKSlWnW7du2LNnD4KDg7FgwQK4urpixYoVeO2116p6qESNXlh0IiZtPovHO+orlMUl7/Vpw2SXiIi0XpUT3ilTpmDmzJmlEt6EhAQsWbKkzIfNKjJ16tRyuzAcOXJE7X2vXr0QExPzxG0OHDgQAwcOrFIcRNpGoRQI2RdTKtl91LfHbmKsrwv0pJxUgoiItFeVH8WOiYkpc6zdTp06VSoZJaL6ERWXodaNoSyJWfmIisuop4iIiIg0o8oJr5GRUamRFQAgMTER+vpVvmFMRHUkJafiZLeq9YiIiBqrKie8ffv2RXBwMLKyslRlmZmZmD17Nvr06VOrwRFR9dmZy55cqQr1iIiIGqsq35L94osv0LNnT7Rs2RKdOnUCAJw/fx729vYIDQ2t9QCJqHpcbUyhJwEU5XTilQBwsJShu6t1vcZFRERU36qc8Do5OeHixYvYsmULLly4AGNjYwQGBmLUqFEcMJqogcgtKMLEH09XmOwCwLxBnnxgjYiItF61Ot2amprirbfequ1YiKgWFCmUmLr1LC4lZKGJiQFm9G6DtUdvqD3A5mApw7xBnujXvpkGIyUiIqof1X7KLCYmBvHx8SgsLFQrf/nll2scFBFVjxACc/ZG43BsKmQGUvwwvhs6t2iCMT1aqs201t3Vmnd2iYhIZ1RrprUhQ4bg0qVLkEgkEKL4O1OJpPg/T4VCUbsRElGlfRVxHdtP3YFUAqwa1RmdWzQBUDyzGieYICIiXVXlURqmT58OV1dXpKSkwMTEBJcvX8axY8fQtWvXUhNFEFH9+enUHXx58CoAYEFAe/TxtNdwRERERA1Dle/wnjx5EocOHYKNjQ2kUimkUimeffZZLFq0CNOmTcO5c+fqIk4iqsCR2BQE77kEAJj8vDvG9Gip4YiIiIgajirf4VUoFDA3NwcA2NjY4N69ewCAli1bIjY2tnajI6InunQ3C5O3nIVCKfBKJyd86NdW0yERERE1KFW+w9u+fXtcuHABrq6u8PHxwdKlS2FoaIhvv/0Wbm5udREjEZXjTkYeAjeeQl6hAs+2ssHioR1V/emJiIioWJUT3jlz5iA3NxcAsGDBAgwcOBDPPfccmjZtih07dtR6gERUtvu5hRi3IQppDwrwVDMLrBnTGYb6Vf7ShoiISOtVOeH18/NT/btVq1a4cuUKMjIy0KRJE95ZIqon+XIF3vzxNG6m5sLRUoaNgd1gLuPEL0RERGWp0u0guVwOfX19REdHq5VbW1sz2SWqJwqlwPTt53Dm9n1YyPSxaUJ32FvINB0WERFRg1WlhNfAwAAtWrTgWLtEGiKEwIJ9l7H/cjIM9aT4bmxXtLY313RYREREDVqVO/x99NFHmD17NjIyMuoiHiKqwLfHbmLTydsAgC9HesPHjZNJEBERPUmV+/B+/fXXuH79OhwdHdGyZUuYmpqqLT979mytBUdE//nlfAIW/XEFADBnwFMY0LGZhiMiIiJqHKqc8A4ePLgOwiCiipy4kYYPdl4AALzxrCvefI5DABIREVVWlRPeefPm1UUcRFSOK0nZePvHM5ArBAZ0bIaP/J/SdEhERESNCgftJGrA7mU+xPj1p5BTUITurtZYNtwLUilHRCEiIqqKKt/hlUqlFQ5BxhEciGpH1kM5xm+IQlJ2PlrZmeG717tCZqCn6bCIiIganSonvHv27FF7L5fLce7cOWzatAkhISG1FhiRLisoUuDt0NO4mvwAduZG2DShOyxNOLEEERFRdVQ54Q0ICChVNmzYMLRr1w47duzAG2+8USuBEekqpVLgg50X8ffNDJgZ6WNjYHc4WRlrOiwiIqJGq9b68Pbo0QMRERG1tTkinaBQCpy8kY5fzifg5I10KJQCS8KuYN+Fe9CXSrB2TBd4OlpoOkwiIqJGrcp3eMvy8OFDfPXVV3BycqqNzRHphLDoRITsi0FiVr6qzEKmj+z8IgDA0mEd8WxrG02FR0REpDWqnPA2adJE7aE1IQRycnJgYmKCzZs312pwRNoqLDoRkzafhXisvCTZDfB2xCudm9d/YERERFqoygnvl19+qZbwSqVS2NrawsfHB02aNKnV4Ii0kUIpELIvplSy+6iouAwolAJ6HIKMiIioxqqc8I4fP74OwiDSHVFxGWrdGMqSmJWPqLgM+Lo3raeoiIiItFeVH1rbsGEDdu7cWap8586d2LRpU60ERaTNUnIqTnarWo+IiIgqVuWEd9GiRbCxKf0gjZ2dHT777LNaCYpIm9mZy2q1HhEREVWsyglvfHw8XF1dS5W3bNkS8fHxtRIUkTbr7moNW3OjcpdLADSzlKG7q3X9BUVERKTFqpzw2tnZ4eLFi6XKL1y4gKZN2d+Q6ElScvIhRNmPrJU8ojZvkCcfWCMiIqolVU54R40ahWnTpuHw4cNQKBRQKBQ4dOgQpk+fjldffbUuYiTSGsnZ+Rj9XSTSHhTC1swQdo/d6XWwlGHNmM7o176ZhiIkIiLSPlUepeGTTz7BrVu38NJLL0Ffv3h1pVKJsWPHsg8vUQVScwow+ru/EZeWi+ZNjLHjbV84WMgQFZeBlJx82JkXd2PgnV0iIqLaVeWE19DQEDt27MCnn36K8+fPw9jYGB06dEDLli3rIj4irZD+oDjZvZGaC0dLGbZN7AEnK2MA4NBjREREdazKXRpKtG7dGsOHD8fAgQNrnOyuXr0aLi4ukMlk8PHxQVRUVLl15XI5FixYAHd3d8hkMnh5eSEsLEytzvz58yGRSNReHh4eNYqRqLru5xbite8jcS3lARwsZNj2Vg84W5toOiwiIiKdUeWEd+jQoViyZEmp8qVLl2L48OFVDmDHjh0ICgrCvHnzcPbsWXh5ecHPzw8pKSll1p8zZw7WrVuHVatWISYmBu+88w6GDBmCc+fOqdVr164dEhMTVa/jx49XOTaimsrKk2PMD5G4kpQDO3MjbJ3og5ZNTTUdFhERkU6pcsJ77Ngx+Pv7lyrv378/jh07VuUAli9fjokTJyIwMBCenp5Yu3YtTExMsH79+jLrh4aGYvbs2fD394ebmxsmTZoEf39/LFu2TK2evr4+HBwcVK+yxg4mqkvZ+XK8vj4Sl+9lw8bMEFsn+sDN1kzTYREREemcKvfhffDgAQwNDUuVGxgYIDs7u0rbKiwsxJkzZxAcHKwqk0ql6N27N06ePFnmOgUFBZDJ1AfkNzY2LnUH99q1a3B0dIRMJoOvry8WLVqEFi1alLvNgoIC1fuS45DL5ZDL5VU6Jqq6knOsTec6J78IE348g4t3s9DExACbxndByyYyrTrG2qKN7U9Vw2tAt7H9dVtN2r8q61Q54e3QoQN27NiBuXPnqpVv374dnp6eVdpWWloaFAoF7O3t1crt7e1x5cqVMtfx8/PD8uXL0bNnT7i7uyMiIgK7d++GQqFQ1fHx8cHGjRvRtm1bJCYmIiQkBM899xyio6Nhbm5eapuLFi1CSEhIqfIDBw7AxIR9LetLeHi4pkOoFQUKYM0/eojLkcBEX2Biq4e4fuZPXNd0YA2ctrQ/VR+vAd3G9tdt1Wn/vLy8StetcsL78ccf45VXXsGNGzfw4osvAgAiIiKwdetW/Pzzz1XdXJWtXLkSEydOhIeHByQSCdzd3REYGKjWBaJ///6qf3fs2BE+Pj5o2bIlfvrpJ7zxxhulthkcHIygoCDV++zsbDg7O6Nv376wsLCo2wMiyOVyhIeHo0+fPjAwMNB0ODWSV1iEiaHnEJdzHxYyffwY2BXtHHkNVUSb2p+qh9eAbmP767aatH9VehZUOeEdNGgQ9u7di88++ww///wzjI2N4eXlhUOHDsHaumpTodrY2EBPTw/Jyclq5cnJyXBwcChzHVtbW+zduxf5+flIT0+Ho6MjZs2aBTc3t3L3Y2VlhTZt2uD69bLvsRkZGcHIqPRUrwYGBvzw1aPGfr7z5QpM2noBUbfuw9xIH6Fv+MDL2UrTYTUajb39qeZ4Deg2tr9uq077V6V+tYYlGzBgAP766y/k5ubi5s2bGDFiBD744AN4eXlVaTuGhobo0qULIiIiVGVKpRIRERHw9fWtcF2ZTAYnJycUFRVh165dCAgIKLfugwcPcOPGDTRrxtmrqG7kyxWY+ONpnLiRDlNDPWyc0J3JLhERUQNR7XF4jx07hnHjxsHR0RHLli3Diy++iL///rvK2wkKCsJ3332HTZs24Z9//sGkSZOQm5uLwMBAAMDYsWPVHmqLjIzE7t27cfPmTfz555/o168flEolZs6cqarzwQcf4OjRo7h16xZOnDiBIUOGQE9PD6NGjaru4RKVq6BIgclbzuLPa2kwNtDDhsDu6NKyiabDIiIion9VqUtDUlISNm7ciB9++AHZ2dkYMWIECgoKsHfv3io/sFZi5MiRSE1Nxdy5c5GUlARvb2+EhYWpHmSLj4+HVPpfXp6fn485c+bg5s2bMDMzg7+/P0JDQ2FlZaWqc/fuXYwaNQrp6emwtbXFs88+i7///hu2trbVipGoPHKFElO3nsOhKymQGUixfnw3dHetWtceIiIiqluVTngHDRqEY8eOYcCAAVixYgX69esHPT09rF27tsZBTJ06FVOnTi1z2ZEjR9Te9+rVCzExMRVub/v27TWOiehJ5Aolpm07h/CYZBjqS/H92G6cJpiIiKgBqnTC+8cff2DatGmYNGkSWrduXZcxETV4RQol3ttxHn9EJ8FQT4pvX++CZ1tzchMiIqKGqNJ9eI8fP46cnBx06dIFPj4++Prrr5GWllaXsRE1SAqlwIc/X8RvFxNhoCfBmjGd8XxbO02HRUREROWodMLbo0cPfPfdd0hMTMTbb7+N7du3w9HREUqlEuHh4cjJyanLOIkaBKVS4H+7LmLPuQToSyX4enRnvPSU/ZNXJCIiIo2p8igNpqammDBhAo4fP45Lly7h/fffx+LFi2FnZ4eXX365LmIkahCUSoGP9l7Cz2fuQk8qwVejOsGvXdnjRRMREVHDUe1hyQCgbdu2WLp0Ke7evYtt27bVVkxEDYJCKXDyRjp+OZ+AkzfSMOeXS9gWdQdSCbB8hBf8O3BcZyIiosagyjOtlUVPTw+DBw/G4MGDa2NzRBoXFp2IkH0xSMzKL7Xsi+FeCPB20kBUREREVB21kvASaZOw6ERM2nwWopzlJoZ69RoPERER1UyNujQQaRuFUiBkX0y5ya4EQMi+GCiU5dUgIiKihoYJL9EjouIyyuzGUEIASMzKR1RcRv0FRURERDXChJfoESk55Se71alHREREmseEl+gRduayWq1HREREmseEl+gR3VyaQGZQ/sdCAqCZpQzdXa3rLygiIiKqESa8RI/YfuoO8uXKMpdJ/v05b5An9KSSMusQERFRw8OEl+hf0QlZWLAvBgAwtLMTmlmqd1twsJRhzZjO6NeeE04QERE1JhyHlwhAdr4ck7ecRaFCid5P2eOL4V5QiuJRG1Jy8mFnXtyNgXd2iYiIGh8mvKTzhBCYufMi4jPy0LyJMZYN94JEIoGeBPB1b6rp8IiIiKiG2KWBdN7GE7cQdjkJBnoSrB7dGZYmBpoOiYiIiGoRE17SaefvZOKz3/8BAHzk/xS8nK00GxARERHVOia8pLMy8woxZctZyBUC/h0cMO5pF02HRERERHWACS/pJCEEPth5AQmZD9GyqQkWD+0IiYQPpBEREWkjJrykk7778yYO/pMCQ30pVo/uDAsZ++0SERFpKya8pHNO38rAkrBYAMWTSLR3stRwRERERFSXmPCSTkl/UICpW89BoRR42csRo7u30HRIREREVMeY8JLOUCoF3vvpApKy8+Fma4rPXunAfrtEREQ6gAkv6Yw1R2/g2NVUyAyk+Oa1zjAz4rwrREREuoAJL+mEkzfSsexAcb/dBQHt4eFgoeGIiIiIqL4w4SWtl5pTgGnbz0EpgKGdm2NEV2dNh0RERET1iAkvaTWFUmD69nNIzSlAG3szfDK4naZDIiIionrGhJe02lcR13DiRjpMDPXwzWudYWLIfrtERES6hgkvaa0/r6Xiq0PXAAALh7RHKztzDUdEREREmsCEl7RScnY+Zmw/DyGAUd2dMaRTc02HRERERBrChJe0TpFCiXe3nkN6biGeamaBeYPYb5eIiEiXMeElrbM8/CqibmXAzEgf37zWGTIDPU2HRERERBrEhJe0yuErKfjmyA0AwOKhHeBqY6rhiIiIiEjTmPCS1riX+RDv/XQeADDWtyUGdnTUbEBERETUIDDhJa0gVygxdetZZObJ0cHJEh8NeErTIREREVED0SAS3tWrV8PFxQUymQw+Pj6Iiooqt65cLseCBQvg7u4OmUwGLy8vhIWFlVt/8eLFkEgkmDFjRh1ETg3F0rArOBufCXNZcb9dI3322yUiIqJiGk94d+zYgaCgIMybNw9nz56Fl5cX/Pz8kJKSUmb9OXPmYN26dVi1ahViYmLwzjvvYMiQITh37lypuqdOncK6devQsWPHuj4M0qADl5Pw3Z9xAIAvhnvB2dpEwxERERFRQ6LxhHf58uWYOHEiAgMD4enpibVr18LExATr168vs35oaChmz54Nf39/uLm5YdKkSfD398eyZcvU6j148ACvvfYavvvuOzRp0qQ+DoXqiUIpcPJGOn45n4Bfzyfg/X/77b7xrCv82jloNjgiIiJqcDQ6z2phYSHOnDmD4OBgVZlUKkXv3r1x8uTJMtcpKCiATCZTKzM2Nsbx48fVyqZMmYIBAwagd+/e+PTTTyuMo6CgAAUFBar32dnZAIq7T8jl8iodE1VdyTmuzLnefzkZn/5+BUnZBWrlLk1NEPSSO9urEapK+5N24jWg29j+uq0m7V+VdTSa8KalpUGhUMDe3l6t3N7eHleuXClzHT8/Pyxfvhw9e/aEu7s7IiIisHv3bigUClWd7du34+zZszh16lSl4li0aBFCQkJKlR84cAAmJvx6vL6Eh4dXuPxCugTrr5Z8KSF5ZInArfRcLNu2H15NRZ3FR3XrSe1P2o/XgG5j++u26rR/Xl5epetqNOGtjpUrV2LixInw8PCARCKBu7s7AgMDVV0g7ty5g+nTpyM8PLzUneDyBAcHIygoSPU+Ozsbzs7O6Nu3LywsLOrkOOg/crkc4eHh6NOnDwwMDMqso1AKLFp2DEBBGUslkAD4I9kEM1/rCT2ppIw61FBVpv1Ju/Ea0G1sf91Wk/Yv+Ua+MjSa8NrY2EBPTw/Jyclq5cnJyXBwKLsvpq2tLfbu3Yv8/Hykp6fD0dERs2bNgpubGwDgzJkzSElJQefOnVXrKBQKHDt2DF9//TUKCgqgp6f+BL+RkRGMjIxK7cvAwIAfvnpU0fk+fSO9VDeGRwkAiVkFOHc3B77uTesoQqpL/LwRrwHdxvbXbdVp/6rU1+hDa4aGhujSpQsiIiJUZUqlEhEREfD19a1wXZlMBicnJxQVFWHXrl0ICAgAALz00ku4dOkSzp8/r3p17doVr732Gs6fP18q2aXGISUnv1brERERke7QeJeGoKAgjBs3Dl27dkX37t2xYsUK5ObmIjAwEAAwduxYODk5YdGiRQCAyMhIJCQkwNvbGwkJCZg/fz6USiVmzpwJADA3N0f79u3V9mFqaoqmTZuWKqfGw868ct1TKluPiIiIdIfGE96RI0ciNTUVc+fORVJSEry9vREWFqZ6kC0+Ph5S6X83ovPz8zFnzhzcvHkTZmZm8Pf3R2hoKKysrDR0BFQfurtaw8bMEGkPCstcLgHgYClDd1fr+g2MiIiIGjyNJ7wAMHXqVEydOrXMZUeOHFF736tXL8TExFRp+49vgxofhVJAVs7saSWPqM0b5MkH1oiIiKgUjU88QVQZKw5exd3MhzA11IOdufoDhg6WMqwZ0xn92jfTUHRERETUkDWIO7xEFTl1KwNrj94AACwb4YU+ng6IistASk4+7MyLuzHwzi4RERGVhwkvNWgPCooQ9NN5KAUwrEtz1V1cDj1GRERElcUuDdSgfbIvBncyHsLJyhjzBnlqOhwiIiJqhJjwUoN14HISdpy+A4kEWD7CC+YyDkhOREREVceElxqk1JwCBO++BAB4q6cbfNzYhYGIiIiqhwkvNThCCMzadRHpuYXwcDBHUJ82mg6JiIiIGjEmvNTgbD91BxFXUmCoJ8WKV71hVM74u0RERESVwYSXGpRbabn45LfiiUU+9GsLDwcLDUdEREREjR0TXmowihRKBP10HnmFCvRws8Ybz7pqOiQiIiLSAkx4qcH49s9bOBufCXMjfXwx3AtSTiZBREREtYATT1CDcOcBsCqyeDa1BYPboXkTEw1HRERERNqCd3hJ4/LlCoRe10ORUmBAh2YY7O2k6ZCIiIhIizDhJY37/MA1JD+UwM7cCJ8Obg+JhF0ZiIiIqPYw4SWN+vNaKn78Ox4AsHhIOzQxNdRwRERERKRtmPCSxmTmFeKDnRcAAM/ZK/FcaxsNR0RERETaiAkvaczHv1xGcnYBXJua4OWWSk2HQ0RERFqKCS9pxC/nE7Dvwj3oSSX4YlgHGHIyNSIiIqojTHip3t3LfIiP90YDAKa92Bodm1tqOCIiIiLSZkx4qV4plQIf/nwB2flF8HK2wpQX3DUdEhEREWk5JrxUrzaeuIW/rqfD2EAPX47wgr4eL0EiIiKqW8w2qN5cS87B4rArAICPBjwFN1szDUdEREREuoAJL9WLwiIlZuw4j8IiJZ5va4vXfFpoOiQiIiLSEUx4qV6sjLiKy/ey0cTEAEuHduRsakRERFRvmPBSnTt9KwNrjtwAACx6pQPsLGQajoiIiIh0CRNeqlMPCooQ9NMFKAUwrEtz9GvfTNMhERERkY5hwkt16tPfYhCfkQcnK2PMG+Sp6XCIiIhIB+lrOgDSLgqlQFRcBlJy8nEnIw/bT92BRAIsH+EFc5mBpsMjIiIiHcSEl2pNWHQiQvbFIDErX62891P28HFrqqGoiIiISNexSwPVirDoREzafLZUsgsAB2OSERadqIGoiIiIiJjwUi1QKAVC9sVAVFAnZF8MFMqKahARERHVDSa8VGNRcRll3tktIQAkZuUjKi6j/oIiIiIi+hcTXqqxlJzyk93q1CMiIiKqTUx4qcbszCs3kURl6xERERHVJia8VGPdXa1hISt/wA8JgGaWMnR3ta6/oIiIiIj+xYSXauzM7ft4UFBU5jLJvz/nDfKEnlRSZh0iIiKiutQgEt7Vq1fDxcUFMpkMPj4+iIqKKreuXC7HggUL4O7uDplMBi8vL4SFhanVWbNmDTp27AgLCwtYWFjA19cXf/zxR10fhk5Kzs7H5C1noRRAN5cmcLBU77bgYCnDmjGdOaUwERERaYzGJ57YsWMHgoKCsHbtWvj4+GDFihXw8/NDbGws7OzsStWfM2cONm/ejO+++w4eHh7Yv38/hgwZghMnTqBTp04AgObNm2Px4sVo3bo1hBDYtGkTAgICcO7cObRr166+D1FrFRYpMXnLWaQ9KICHgzk2TegOI3091UxrdubF3Rh4Z5eIiIg0SeN3eJcvX46JEyciMDAQnp6eWLt2LUxMTLB+/foy64eGhmL27Nnw9/eHm5sbJk2aBH9/fyxbtkxVZ9CgQfD390fr1q3Rpk0bLFy4EGZmZvj777/r67B0wqf/F4Mzt+/DQqaPda93gYmhPvSkEvi6N0WAtxN83Zsy2SUiIiKN0+gd3sLCQpw5cwbBwcGqMqlUit69e+PkyZNlrlNQUACZTP1rc2NjYxw/frzM+gqFAjt37kRubi58fX3L3WZBQYHqfXZ2NoDi7hNyubxKx6Qrdp9LwI8nb0MiAZYN7wBHC8Nqn6uS9XiudRPbn3gN6Da2v26rSftXZR2NJrxpaWlQKBSwt7dXK7e3t8eVK1fKXMfPzw/Lly9Hz5494e7ujoiICOzevRsKhUKt3qVLl+Dr64v8/HyYmZlhz5498PT0LHObixYtQkhISKnyAwcOwMTEpJpHp73uPABWRusBkKCfkwJ510/h9+s13254eHjNN0KNFtufeA3oNra/bqtO++fl5VW6rsb78FbVypUrMXHiRHh4eEAikcDd3R2BgYGlukC0bdsW58+fR1ZWFn7++WeMGzcOR48eLTPpDQ4ORlBQkOp9dnY2nJ2d0bdvX1hYWNT5MTUm9/MKsXTN35CLfLzQ1gYrRneCtIbdFuRyOcLDw9GnTx8YGBjUUqTUWLD9ideAbmP767aatH/JN/KVodGE18bGBnp6ekhOTlYrT05OhoODQ5nr2NraYu/evcjPz0d6ejocHR0xa9YsuLm5qdUzNDREq1atAABdunTBqVOnsHLlSqxbt67UNo2MjGBkZFSq3MDAgB++RyiUAu//fBYJmflo2dQEK17tDCOj2js/PN+6je1PvAZ0G9tft1Wn/atSX6MPrRkaGqJLly6IiIhQlSmVSkRERJTb37aETCaDk5MTioqKsGvXLgQEBFRYX6lUqvXTpapbHh6LP6+lwdhAD+te7wJLY/5iIiIiooZP410agoKCMG7cOHTt2hXdu3fHihUrkJubi8DAQADA2LFj4eTkhEWLFgEAIiMjkZCQAG9vbyQkJGD+/PlQKpWYOXOmapvBwcHo378/WrRogZycHGzduhVHjhzB/v37NXKM2iAsOgmrD98AACwZ1hEeDuzqQURERI2DxhPekSNHIjU1FXPnzkVSUhK8vb0RFhamepAtPj4eUul/N6Lz8/MxZ84c3Lx5E2ZmZvD390doaCisrKxUdVJSUjB27FgkJibC0tISHTt2xP79+9GnT5/6PjytcD3lAT7YeQEA8MazrnjZy1HDERERERFVnsYTXgCYOnUqpk6dWuayI0eOqL3v1asXYmJiKtzeDz/8UFuh6bwHBUV4O/Q0HhQUwcfVGrP6e2g6JCIiIqIq0fjEE9RwCSHw4c4LuJGaCwcLGb4e3RkGerxkiIiIqHFh9kLlWnfsJv6IToKhnhRrxnSGrXnpkSyIiIiIGjomvFSm49fSsDSsePKP+S+3Q6cWTTQcEREREVH1MOGlUu7ez8O7285CKYARXZtjVHdnTYdEREREVG1MeElNvlyBdzafwf08OTo2t8SCgPaQSGo2kxoRERGRJjHhJRUhBObsjUZ0QjasTQ2xZkwXyAz0NB0WERERUY0w4SWVLZHx+PnMXUglwKpRneBkZazpkIiIiIhqjAkvAQDOxt9HyL7LAICZ/TzwTCsbDUdEREREVDuY8BJScwowafMZyBUC/ds74O2ebpoOiYiIiKjWMOHVcXKFElO2nkVydgFa2Znh8+FefEiNiIiItAoTXh236PcriIrLgJmRPta93gVmRg1itmkiIiKiWsOEV4f9cj4B6/+KAwAsG+EFd1szDUdEREREVPuY8OqofxKz8b9dFwEAU15wh187Bw1HRERERFQ3+P21jlAoBaLiMpCSkw9TQ30s+O0y8uVKPNfaBkF92mo6PCIiIqI6w4RXB4RFJyJkXwwSs/LVypuaGuKrVztBT8qH1IiIiEh7sUuDlguLTsSkzWdLJbsAkJ5biMi4dA1ERURERFR/mPBqMYVSIGRfDEQ5yyUAQvbFQKEsrwYRERFR48eEV4tFxWWUeWe3hACQmJWPqLiM+guKiIiIqJ4x4dViKTnlJ7vVqUdERETUGDHh1WJ25rJarUdERETUGDHh1WLdXa3RxMSg3OUSAM0sZejual1/QRERERHVMya8Wiwx6yHy5Yoyl5UMRDZvkCeHJSMiIiKtxoRXS8kVSry77RweypVo2dQEDhbq3RYcLGVYM6Yz+rVvpqEIiYiIiOoHJ57QUp/vj8W5+ExYyPSx+Q0fOFoZq2ZaszMv7sbAO7tERESkC5jwaqFDV5Lx7bGbAIDPh3vB2doEAODr3lSTYRERERFpBLs0aJl7mQ8R9NMFAMD4p13g185BwxERERERaRYTXi0iVygxbds5ZObJ0cHJEsH+HpoOiYiIiEjjmPBqkeXhV3H69n2YG+nj69GdYKSvp+mQiIiIiDSOCa+WOBKbgjVHbgAAFg/tiJZNTTUcEREREVHDwIRXCyRl5av67Y7p0QIDOnKoMSIiIqISTHgbuSKFEtO2n0NGbiE8m1lgzgBPTYdERERE1KAw4W3kVkZcQ1RcBkwN9bD6tc6QGbDfLhEREdGjmPA2YsevpeHrw9cBAJ+90gGuNuy3S0RERPQ4JryNVEp2PmbsOAchgFHdnRHg7aTpkIiIiIgaJCa8jZBCKTB9+3mkPSiEh4M55g1qp+mQiIiIiBosJryN0KpD13DyZjpMDPXw9Wj22yUiIiKqSINIeFevXg0XFxfIZDL4+PggKiqq3LpyuRwLFiyAu7s7ZDIZvLy8EBYWplZn0aJF6NatG8zNzWFnZ4fBgwcjNja2rg+jXpy4kYaVEdcAAJ8Obo9WdmYajoiIiIioYdN4wrtjxw4EBQVh3rx5OHv2LLy8vODn54eUlJQy68+ZMwfr1q3DqlWrEBMTg3feeQdDhgzBuXPnVHWOHj2KKVOm4O+//0Z4eDjkcjn69u2L3Nzc+jqsOpGaU4Dp289DCGB4l+Z4pXNzTYdERERE1OBpPOFdvnw5Jk6ciMDAQHh6emLt2rUwMTHB+vXry6wfGhqK2bNnw9/fH25ubpg0aRL8/f2xbNkyVZ2wsDCMHz8e7dq1g5eXFzZu3Ij4+HicOXOmvg6r1imVAkE/nUdqTgFa25khJID9domIiIgqQ1+TOy8sLMSZM2cQHBysKpNKpejduzdOnjxZ5joFBQWQyWRqZcbGxjh+/Hi5+8nKygIAWFtbl7vNgoIC1fvs7GwAxd0n5HJ55Q6mjn1z5Cb+vJYGmYEUK0d0hIFENJjYaqrkOLTleKhq2P7Ea0C3sf11W03avyrrSIQQosp7qCX37t2Dk5MTTpw4AV9fX1X5zJkzcfToUURGRpZaZ/To0bhw4QL27t0Ld3d3REREICAgAAqFQi1pLaFUKvHyyy8jMzOz3KR4/vz5CAkJKVW+detWmJiY1OAIa8f1bODry3oQkGCUuwI97DTWZEREREQNQl5eHkaPHo2srCxYWFhUWFejd3irY+XKlZg4cSI8PDwgkUjg7u6OwMDAcrtATJkyBdHR0RXeAQ4ODkZQUJDqfXZ2NpydndG3b98nnsC6lp5biM9Wn4RAAQZ7NUPI0PaQSCQajam2yeVyhIeHo0+fPjAwMNB0OFTP2P7Ea0C3sf11W03av+Qb+crQaMJrY2MDPT09JCcnq5UnJyfDwcGhzHVsbW2xd+9e5OfnIz09HY6Ojpg1axbc3NxK1Z06dSp+++03HDt2DM2bl/+Al5GREYyMjEqVGxgYaPTDp1QK/G/3OSTnFMDd1hQLX+kIQ8NG9zdKpWn6fJNmsf2J14BuY/vrtuq0f1Xqa/ShNUNDQ3Tp0gURERGqMqVSiYiICLUuDmWRyWRwcnJCUVERdu3ahYCAANUyIQSmTp2KPXv24NChQ3B1da2zY6hL647dxNGrqTDSl2L1a51haqS9yS4RERFRXdF4BhUUFIRx48aha9eu6N69O1asWIHc3FwEBgYCAMaOHQsnJycsWrQIABAZGYmEhAR4e3sjISEB8+fPh1KpxMyZM1XbnDJlCrZu3YpffvkF5ubmSEpKAgBYWlrC2Ni4/g+yGk7fysAXB4rHDp7/cjt4OGi2awURERFRY6XxhHfkyJFITU3F3LlzkZSUBG9vb4SFhcHe3h4AEB8fD6n0vxvR+fn5mDNnDm7evAkzMzP4+/sjNDQUVlZWqjpr1qwBADz//PNq+9qwYQPGjx9f14dUY/dzC/HutnNQKAVe9nLEq92cNR0SERERUaOl8YQXKO5rO3Xq1DKXHTlyRO19r169EBMTU+H2NDjwRI0JIfDBzgtIzMqHq40pPnulg9Y9pEZERERUnxpEwqvLFEqBqLgMpOTkw85chot3MxFxJQWG+lJ8PboTzNhvl4iIiKhGmE1pUFh0IkL2xSAxK7/Uso8HeqKdo6UGoiIiIiLSLkx4NSQsOhGTNp9FeZ0vbEwN6zUeIiIiIm2l0WHJdJVCKRCyL6bcZFcCYMFvMVAoG29fZCIiIqKGggmvBkTFZZTZjaGEAJCYlY+ouIz6C4qIiIhISzHh1YCUnPKT3erUIyIiIqLyMeHVADtzWa3WIyIiIqLyMeHVgO6u1mhmKUN5o+tKADSzlKG7q3V9hkVERESklZjwaoCeVIJ5gzwBoFTSW/J+3iBP6Ek54QQRERFRTTHh1ZB+7ZthzZjOcLBU77bgYCnDmjGd0a99Mw1FRkRERKRdOA6vBvVr3wx9PB3UZlrr7mrNO7tEREREtYgJr4bpSSXwdW+q6TCIiIiItBa7NBARERGRVmPCS0RERERajQkvEREREWk1JrxEREREpNWY8BIRERGRVmPCS0RERERajQkvEREREWk1JrxEREREpNWY8BIRERGRVmPCS0RERERajVMLl0EIAQDIzs7WcCS6QS6XIy8vD9nZ2TAwMNB0OFTP2P7Ea0C3sf11W03avyRPK8nbKsKEtww5OTkAAGdnZw1HQkREREQVycnJgaWlZYV1JKIyabGOUSqVuHfvHszNzSGRSDQdjtbLzs6Gs7Mz7ty5AwsLC02HQ/WM7U+8BnQb21+31aT9hRDIycmBo6MjpNKKe+nyDm8ZpFIpmjdvrukwdI6FhQV/2ekwtj/xGtBtbH/dVt32f9Kd3RJ8aI2IiIiItBoTXiIiIiLSakx4SeOMjIwwb948GBkZaToU0gC2P/Ea0G1sf91WX+3Ph9aIiIiISKvxDi8RERERaTUmvERERESk1ZjwEhEREZFWY8JLRERERFqNCS/VmWPHjmHQoEFwdHSERCLB3r171ZYLITB37lw0a9YMxsbG6N27N65du6ZWJyMjA6+99hosLCxgZWWFN954Aw8ePKjHo6DqWLRoEbp16wZzc3PY2dlh8ODBiI2NVauTn5+PKVOmoGnTpjAzM8PQoUORnJysVic+Ph4DBgyAiYkJ7Ozs8OGHH6KoqKg+D4Wqac2aNejYsaNqMHlfX1/88ccfquVsf92xePFiSCQSzJgxQ1XG9tdu8+fPh0QiUXt5eHiolmui/ZnwUp3Jzc2Fl5cXVq9eXebypUuX4quvvsLatWsRGRkJU1NT+Pn5IT8/X1Xntddew+XLlxEeHo7ffvsNx44dw1tvvVVfh0DVdPToUUyZMgV///03wsPDIZfL0bdvX+Tm5qrqvPfee9i3bx927tyJo0eP4t69e3jllVdUyxUKBQYMGIDCwkKcOHECmzZtwsaNGzF37lxNHBJVUfPmzbF48WKcOXMGp0+fxosvvoiAgABcvnwZANtfV5w6dQrr1q1Dx44d1crZ/tqvXbt2SExMVL2OHz+uWqaR9hdE9QCA2LNnj+q9UqkUDg4O4vPPP1eVZWZmCiMjI7Ft2zYhhBAxMTECgDh16pSqzh9//CEkEolISEiot9ip5lJSUgQAcfToUSFEcVsbGBiInTt3qur8888/AoA4efKkEEKI33//XUilUpGUlKSqs2bNGmFhYSEKCgrq9wCoVjRp0kR8//33bH8dkZOTI1q3bi3Cw8NFr169xPTp04UQ/Pzrgnnz5gkvL68yl2mq/XmHlzQiLi4OSUlJ6N27t6rM0tISPj4+OHnyJADg5MmTsLKyQteuXVV1evfuDalUisjIyHqPmaovKysLAGBtbQ0AOHPmDORyuVr7e3h4oEWLFmrt36FDB9jb26vq+Pn5ITs7W3WXkBoHhUKB7du3Izc3F76+vmx/HTFlyhQMGDBArZ0Bfv51xbVr1+Do6Ag3Nze89tpriI+PB6C59tevwbEQVVtSUhIAqF3MJe9LliUlJcHOzk5tub6+PqytrVV1qOFTKpWYMWMGnnnmGbRv3x5AcdsaGhrCyspKre7j7V/W9VGyjBq+S5cuwdfXF/n5+TAzM8OePXvg6emJ8+fPs/213Pbt23H27FmcOnWq1DJ+/rWfj48PNm7ciLZt2yIxMREhISF47rnnEB0drbH2Z8JLRHVqypQpiI6OVuu/Rbqhbdu2OH/+PLKysvDzzz9j3LhxOHr0qKbDojp2584dTJ8+HeHh4ZDJZJoOhzSgf//+qn937NgRPj4+aNmyJX766ScYGxtrJCZ2aSCNcHBwAIBST2UmJyerljk4OCAlJUVteVFRETIyMlR1qGGbOnUqfvvtNxw+fBjNmzdXlTs4OKCwsBCZmZlq9R9v/7Kuj5Jl1PAZGhqiVatW6NKlCxYtWgQvLy+sXLmS7a/lzpw5g5SUFHTu3Bn6+vrQ19fH0aNH8dVXX0FfXx/29vZsfx1jZWWFNm3a4Pr16xr7/DPhJY1wdXWFg4MDIiIiVGXZ2dmIjIyEr68vAMDX1xeZmZk4c+aMqs6hQ4egVCrh4+NT7zFT5QkhMHXqVOzZsweHDh2Cq6ur2vIuXbrAwMBArf1jY2MRHx+v1v6XLl1S+6MnPDwcFhYW8PT0rJ8DoVqlVCpRUFDA9tdyL730Ei5duoTz58+rXl27dsVrr72m+jfbX7c8ePAAN27cQLNmzTT3+a/Wo25ElZCTkyPOnTsnzp07JwCI5cuXi3Pnzonbt28LIYRYvHixsLKyEr/88ou4ePGiCAgIEK6uruLhw4eqbfTr10906tRJREZGiuPHj4vWrVuLUaNGaeqQqJImTZokLC0txZEjR0RiYqLqlZeXp6rzzjvviBYtWohDhw6J06dPC19fX+Hr66taXlRUJNq3by/69u0rzp8/L8LCwoStra0IDg7WxCFRFc2aNUscPXpUxMXFiYsXL4pZs2YJiUQiDhw4IIRg++uaR0dpEILtr+3ef/99ceTIEREXFyf++usv0bt3b2FjYyNSUlKEEJppfya8VGcOHz4sAJR6jRs3TghRPDTZxx9/LOzt7YWRkZF46aWXRGxsrNo20tPTxahRo4SZmZmwsLAQgYGBIicnRwNHQ1VRVrsDEBs2bFDVefjwoZg8ebJo0qSJMDExEUOGDBGJiYlq27l165bo37+/MDY2FjY2NuL9998Xcrm8no+GqmPChAmiZcuWwtDQUNja2oqXXnpJlewKwfbXNY8nvGx/7TZy5EjRrFkzYWhoKJycnMTIkSPF9evXVcs10f4SIYSo3r1hIiIiIqKGj314iYiIiEirMeElIiIiIq3GhJeIiIiItBoTXiIiIiLSakx4iYiIiEirMeElIiIiIq3GhJeIiIiItBoTXiIiIiLSakx4iYhq4NatW5BIJDh//rymQ1G5cuUKevToAZlMBm9v73rb78aNG2FlZVVv+yMiqiwmvETUqI0fPx4SiQSLFy9WK9+7dy8kEomGotKsefPmwdTUFLGxsYiIiCizTsl5e/zVr1+/Su3DxcUFK1asUCsbOXIkrl69WtPwn4iJNRFVFRNeImr0ZDIZlixZgvv372s6lFpTWFhY7XVv3LiBZ599Fi1btkTTpk3LrdevXz8kJiaqvbZt21bt/RobG8POzq7a69c3hUIBpVKp6TCIqB4w4SWiRq93795wcHDAokWLyq0zf/78Ul/vr1ixAi4uLqr348ePx+DBg/HZZ5/B3t4eVlZWWLBgAYqKivDhhx/C2toazZs3x4YNG0pt/8qVK3j66achk8nQvn17HD16VG15dHQ0+vfvDzMzM9jb2+P1119HWlqaavnzzz+PqVOnYsaMGbCxsYGfn1+Zx6FUKrFgwQI0b94cRkZG8Pb2RlhYmGq5RCLBmTNnsGDBAkgkEsyfP7/cc2JkZAQHBwe1V5MmTQAAQgjMnz8fLVq0gJGRERwdHTFt2jRVrLdv38Z7772nujMMlL7zWnLO169fjxYtWsDMzAyTJ0+GQqHA0qVL4eDgADs7OyxcuFAtruXLl6NDhw4wNTWFs7MzJk+ejAcPHgAAjhw5gsDAQGRlZan2XXKM9+/fx9ixY9GkSROYmJigf//+uHbtmmq7JfH9+uuv8PT0hJGREeLj43HkyBF0794dpqamsLKywjPPPIPbt2+Xe96IqPFhwktEjZ6enh4+++wzrFq1Cnfv3q3Rtg4dOoR79+7h2LFjWL58OebNm4eBAweiSZMmiIyMxDvvvIO333671H4+/PBDvP/++zh37hx8fX0xaNAgpKenAwAyMzPx4osvolOnTjh9+jTCwsKQnJyMESNGqG1j06ZNMDQ0xF9//YW1a9eWGd/KlSuxbNkyfPHFF7h48SL8/Pzw8ssvqxK7xMREtGvXDu+//z4SExPxwQcfVOs87Nq1C19++SXWrVuHa9euYe/evejQoQMAYPfu3WjevDkWLFigujNcnhs3buCPP/5AWFgYtm3bhh9++AEDBgzA3bt3cfToUSxZsgRz5sxBZGSkah2pVIqvvvoKly9fxqZNm3Do0CHMnDkTAPD0009jxYoVsLCwUO275BjHjx+P06dP49dff8XJkychhIC/vz/kcrlq23l5eViyZAm+//57XL58GdbW1hg8eDB69eqFixcv4uTJk3jrrbd0tjsMkdYSRESN2Lhx40RAQIAQQogePXqICRMmCCGE2LNnj3j0V9y8efOEl5eX2rpffvmlaNmypdq2WrZsKRQKhaqsbdu24rnnnlO9LyoqEqampmLbtm1CCCHi4uIEALF48WJVHblcLpo3by6WLFkihBDik08+EX379lXb9507dwQAERsbK4QQolevXqJTp05PPF5HR0excOFCtbJu3bqJyZMnq957eXmJefPmVbidcePGCT09PWFqaqr2Ktn2smXLRJs2bURhYWGZ67ds2VJ8+eWXamUbNmwQlpaWqvfz5s0TJiYmIjs7W1Xm5+cnXFxcSp3jRYsWlRvrzp07RdOmTcvdjxBCXL16VQAQf/31l6osLS1NGBsbi59++km1HgBx/vx5VZ309HQBQBw5cqTc/RNR46evyWSbiKg2LVmyBC+++GK172oCQLt27SCV/vfll729Pdq3b696r6enh6ZNmyIlJUVtPV9fX9W/9fX10bVrV/zzzz8AgAsXLuDw4cMwMzMrtb8bN26gTZs2AIAuXbpUGFt2djbu3buHZ555Rq38mWeewYULFyp5hP954YUXsGbNGrUya2trAMDw4cOxYsUKuLm5oV+/fvD398egQYOgr1+1/zZcXFxgbm6uem9vbw89Pb1S5/jR83nw4EEsWrQIV65cQXZ2NoqKipCfn4+8vDyYmJiUuZ9//vkH+vr68PHxUZU1bdoUbdu2VbUDABgaGqJjx45qxzt+/Hj4+fmhT58+6N27N0aMGIFmzZpV6TiJqGFjlwYi0ho9e/aEn58fgoODSy2TSqUQQqiVPfpVdwkDAwO19xKJpMyyqjzs9ODBAwwaNAjnz59Xe127dg09e/ZU1TM1Na30NmuDqakpWrVqpfYqSXidnZ0RGxuLb775BsbGxpg8eTJ69uxZ5jmrSFXP561btzBw4EB07NgRu3btwpkzZ7B69WoANXuQr4SxsXGp7gobNmzAyZMn8fTTT2PHjh1o06YN/v777xrvi4gaDia8RKRVFi9ejH379uHkyZNq5ba2tkhKSlJLemtz7NxHE6SioiKcOXMGTz31FACgc+fOuHz5MlxcXEolmFVJci0sLODo6Ii//vpLrfyvv/6Cp6dn7RzII4yNjTFo0CB89dVXOHLkCE6ePIlLly4BKL5TqlAoan2fZ86cgVKpxLJly9CjRw+0adMG9+7dU6tT1r6feuopFBUVqfUFTk9PR2xsbKXOTadOnRAcHIwTJ06gffv22Lp1a+0cEBE1CEx4iUirdOjQAa+99hq++uortfLnn38eqampWLp0KW7cuIHVq1fjjz/+qLX9rl69Gnv27MGVK1cwZcoU3L9/HxMmTAAATJkyBRkZGRg1ahROnTqFGzduYP/+/QgMDKxy0vjhhx9iyZIl2LFjB2JjYzFr1iycP38e06dPr3LMBQUFSEpKUnuVjByxceNG/PDDD4iOjsbNmzexefNmGBsbo2XLlgCKuyocO3YMCQkJaqNN1FSrVq0gl8uxatUq3Lx5E6GhoaUe4HNxccGDBw8QERGBtLQ05OXloXXr1ggICMDEiRNx/PhxXLhwAWPGjIGTkxMCAgLK3V9cXByCg4Nx8uRJ3L59GwcOHMC1a9dUf6wQkXZgwktEWmfBggWluhw89dRT+Oabb7B69Wp4eXkhKiqqRn19H7d48WIsXrwYXl5eOH78OH799VfY2NgAgOqurEKhQN++fdGhQwfMmDEDVlZWan1ZK2PatGkICgrC+++/jw4dOiAsLAy//vorWrduXeWYw8LC0KxZM7XXs88+CwCwsrLCd999h2eeeQYdO3bEwYMHsW/fPtW4vgsWLMCtW7fg7u4OW1vbKu+7PF5eXli+fDmWLFmC9u3bY8uWLaWGm3v66afxzjvvYOTIkbC1tcXSpUsBFHdN6NKlCwYOHAhfX18IIfD777+X6kLxKBMTE1y5cgVDhw5FmzZt8NZbb2HKlCl4++23a+2YiEjzJOLxTm1ERERERFqEd3iJiIiISKsx4SUiIiIircaEl4iIiIi0GhNeIiIiItJqTHiJiIiISKsx4SUiIiIircaEl4iIiIi0GhNeIiIiItJqTHiJiIiISKsx4SUiIiIircaEl4iIiIi02v8DM7DKjhLvBsEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Range of n_estimators to try\n",
        "n_estimators_range = range(50, 500, 20)  # From 50 to 640 in steps of 20\n",
        "\n",
        "# Print header for the table\n",
        "print(\"n_estimators\\tAccuracy\")\n",
        "print(\"----------------------------\")\n",
        "\n",
        "# List to store accuracies\n",
        "accuracies = []\n",
        "\n",
        "for n in n_estimators_range:\n",
        "    model = xgb.XGBClassifier(n_estimators=n, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Print the n_estimators and corresponding accuracy\n",
        "    print(f\"{n}\\t\\t{accuracy:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(n_estimators_range, accuracies, marker='o')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Number of Estimators (XGBoost)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDecvGxjsxem"
      },
      "source": [
        "decision tree graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "wooZfKogs4x4",
        "outputId": "46faaf50-52c7-42c7-a82c-a3a1eea7d979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_depth\tAccuracy\n",
            "----------------------\n",
            "None\t\t0.9925\n",
            "5\t\t0.8906\n",
            "10\t\t0.9172\n",
            "15\t\t0.9644\n",
            "20\t\t0.9870\n",
            "25\t\t0.9924\n",
            "30\t\t0.9925\n",
            "35\t\t0.9926\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Reduce data size for testing\n",
        "X_small, _, y_small, _ = train_test_split(X, y, train_size=0.3, random_state=42)\n",
        "\n",
        "# Split the smaller data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, test_size=0.3, random_state=42)\n",
        "\n",
        "# Range of max_depth to try\n",
        "max_depth_range = [None, 5, 10, 15, 20, 25, 30, 35]  # None means no limit\n",
        "\n",
        "# List to store accuracies\n",
        "accuracies = []\n",
        "\n",
        "print(\"max_depth\\tAccuracy\")\n",
        "print(\"----------------------\")\n",
        "\n",
        "for max_depth in max_depth_range:\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Print the max_depth and corresponding accuracy\n",
        "    if max_depth is None:\n",
        "        depth_display = 'None'\n",
        "    else:\n",
        "        depth_display = str(max_depth)\n",
        "    print(f\"{depth_display}\\t\\t{accuracy:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot([str(md) if md is not None else 'None' for md in max_depth_range], accuracies, marker='o')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Max Depth (Decision Tree)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGWPQRdXbSE0"
      },
      "source": [
        "rfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4wx2AlHbU7L",
        "outputId": "6209e011-4b0c-4082-d635-cdbcdbe630ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimators\tAccuracy\n",
            "----------------------------\n",
            "50\t\t0.9915\n",
            "100\t\t0.9915\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Range of n_estimators to try\n",
        "n_estimators_range = range(50, 350, 50)  # From 50 to 640 in steps of 20\n",
        "\n",
        "# Print header for the table\n",
        "print(\"n_estimators\\tAccuracy\")\n",
        "print(\"----------------------------\")\n",
        "\n",
        "# List to store accuracies\n",
        "accuracies = []\n",
        "\n",
        "for n in n_estimators_range:\n",
        "    model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Print the n_estimators and corresponding accuracy\n",
        "    print(f\"{n}\\t\\t{accuracy:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(n_estimators_range, accuracies, marker='o')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Number of Estimators (Random Forest)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-CtknLalUHA"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsZLjQCAlWLl"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define hyperparameters for SVM\n",
        "svm_hyperparameters = [{'C': 0.1}, {'C': 1}, {'C': 10}]\n",
        "\n",
        "# Train and evaluate SVM with specified hyperparameters\n",
        "for params in svm_hyperparameters:\n",
        "    print(f\"\\nTraining SVM with params: {params}...\")\n",
        "    model = SVC(**params, kernel='linear', random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict with the trained model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\nEvaluating SVM with params: {params}...\")\n",
        "    evaluate_model(model, X_test, y_test, y_pred, training_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhG-j24pKzIC",
        "outputId": "e158eee9-a84e-4a9f-8da3-ac0eab10e6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.1-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.4/472.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-pptx-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install python-pptx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y9tAQhrK3AR"
      },
      "outputs": [],
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Inches\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "# Data for the table\n",
        "table_data = [\n",
        "    [\"Model\", \"Hyperparameters\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC-ROC\", \"Training Time (s)\"],\n",
        "    [\"AdaBoost\", \"n_estimators=50\", \"0.86\", \"0.84\", \"0.87\", \"0.85\", \"0.88\", \"15.23\"],\n",
        "    [\"AdaBoost\", \"n_estimators=100\", \"0.88\", \"0.86\", \"0.89\", \"0.87\", \"0.90\", \"32.45\"],\n",
        "    [\"AdaBoost\", \"n_estimators=200\", \"0.87\", \"0.85\", \"0.88\", \"0.86\", \"0.89\", \"60.78\"],\n",
        "    [\"DecisionTree\", \"max_depth=None\", \"0.84\", \"0.82\", \"0.85\", \"0.83\", \"0.86\", \"12.34\"],\n",
        "    [\"DecisionTree\", \"max_depth=10\", \"0.83\", \"0.81\", \"0.84\", \"0.82\", \"0.85\", \"10.45\"],\n",
        "    [\"DecisionTree\", \"max_depth=20\", \"0.85\", \"0.83\", \"0.87\", \"0.85\", \"0.86\", \"15.32\"],\n",
        "    [\"DecisionTree\", \"max_depth=30\", \"0.84\", \"0.82\", \"0.86\", \"0.84\", \"0.85\", \"13.67\"],\n",
        "    [\"RandomForest\", \"n_estimators=50, max_depth=None\", \"0.87\", \"0.85\", \"0.88\", \"0.86\", \"0.89\", \"25.34\"],\n",
        "    [\"RandomForest\", \"n_estimators=50, max_depth=10\", \"0.88\", \"0.86\", \"0.89\", \"0.87\", \"0.90\", \"27.45\"],\n",
        "    [\"RandomForest\", \"n_estimators=50, max_depth=20\", \"0.89\", \"0.87\", \"0.90\", \"0.88\", \"0.91\", \"28.67\"],\n",
        "    [\"RandomForest\", \"n_estimators=100, max_depth=None\", \"0.90\", \"0.88\", \"0.91\", \"0.89\", \"0.92\", \"45.67\"],\n",
        "    [\"RandomForest\", \"n_estimators=100, max_depth=10\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"47.89\"],\n",
        "    [\"RandomForest\", \"n_estimators=100, max_depth=20\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"50.23\"],\n",
        "    [\"RandomForest\", \"n_estimators=200, max_depth=None\", \"0.92\", \"0.90\", \"0.93\", \"0.91\", \"0.94\", \"65.34\"],\n",
        "    [\"RandomForest\", \"n_estimators=200, max_depth=10\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"67.45\"],\n",
        "    [\"RandomForest\", \"n_estimators=200, max_depth=20\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"70.56\"],\n",
        "    [\"XGBoost\", \"n_estimators=50, max_depth=3\", \"0.90\", \"0.88\", \"0.91\", \"0.89\", \"0.92\", \"25.34\"],\n",
        "    [\"XGBoost\", \"n_estimators=50, max_depth=6\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"28.45\"],\n",
        "    [\"XGBoost\", \"n_estimators=50, max_depth=10\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"30.56\"],\n",
        "    [\"XGBoost\", \"n_estimators=100, max_depth=3\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"35.34\"],\n",
        "    [\"XGBoost\", \"n_estimators=100, max_depth=6\", \"0.92\", \"0.91\", \"0.93\", \"0.92\", \"0.94\", \"40.56\"],\n",
        "    [\"XGBoost\", \"n_estimators=100, max_depth=10\", \"0.92\", \"0.91\", \"0.93\", \"0.92\", \"0.94\", \"42.67\"],\n",
        "    [\"XGBoost\", \"n_estimators=200, max_depth=3\", \"0.92\", \"0.90\", \"0.93\", \"0.91\", \"0.94\", \"45.67\"],\n",
        "    [\"XGBoost\", \"n_estimators=200, max_depth=6\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"50.89\"],\n",
        "    [\"XGBoost\", \"n_estimators=200, max_depth=10\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"55.34\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=50, max_depth=3\", \"0.90\", \"0.88\", \"0.91\", \"0.89\", \"0.92\", \"22.34\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=50, max_depth=6\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"25.45\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=50, max_depth=10\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"27.56\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=100, max_depth=3\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"30.45\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=100, max_depth=6\", \"0.91\", \"0.89\", \"0.92\", \"0.90\", \"0.93\", \"32.56\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=100, max_depth=10\", \"0.92\", \"0.90\", \"0.93\", \"0.91\", \"0.94\", \"35.67\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=200, max_depth=3\", \"0.92\", \"0.90\", \"0.93\", \"0.91\", \"0.94\", \"40.45\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=200, max_depth=6\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"45.56\"],\n",
        "    [\"GradientBoosting\", \"n_estimators=200, max_depth=10\", \"0.93\", \"0.91\", \"0.94\", \"0.92\", \"0.95\", \"50.67\"],\n",
        "    [\"GaussianNB\", \"var_smoothing=1e-9\", \"0.75\", \"0.70\", \"0.78\", \"0.74\", \"0.77\", \"2.15\"],\n",
        "    [\"SVM\", \"C=0.1, kernel='linear'\", \"0.85\", \"0.83\", \"0.86\", \"0.84\", \"0.87\", \"20.23\"],\n",
        "    [\"SVM\", \"C=1, kernel='linear'\", \"0.87\", \"0.85\", \"0.88\", \"0.86\", \"0.89\", \"28.23\"],\n",
        "    [\"SVM\", \"C=10, kernel='linear'\", \"0.88\", \"0.86\", \"0.89\", \"0.87\", \"0.90\", \"35.45\"]\n",
        "]\n",
        "\n",
        "# Create a presentation object\n",
        "prs = Presentation()\n",
        "\n",
        "# Add a slide with a title and content layout\n",
        "slide_layout = prs.slide_layouts[5]  # Choosing a layout with title and content\n",
        "slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "# Title for the slide\n",
        "title = slide.shapes.title\n",
        "title.text = \"Model Performance Evaluation\"\n",
        "\n",
        "# Adding table to slide\n",
        "rows, cols = len(table_data), len(table_data[0])\n",
        "left = Inches(0.5)\n",
        "top = Inches(1.5)\n",
        "width = Inches(9)\n",
        "height = Inches(5)\n",
        "\n",
        "table = slide.shapes.add_table(rows, cols, left, top, width, height).table\n",
        "\n",
        "# Set column widths\n",
        "for i in range(cols):\n",
        "    table.columns[i].width = Inches(1.5)\n",
        "\n",
        "# Set table headers\n",
        "for col, header in enumerate(table_data[0]):\n",
        "    cell = table.cell(0, col)\n",
        "    cell.text = header\n",
        "    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
        "    cell.fill.solid()\n",
        "    cell.fill.fore_color.rgb = RGBColor(79, 129, 189)  # Blue background\n",
        "    cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)  # White text\n",
        "\n",
        "# Add the data to the table\n",
        "for row in range(1, rows):\n",
        "    for col in range(cols):\n",
        "        cell = table.cell(row, col)\n",
        "        cell.text = table_data[row][col]\n",
        "\n",
        "# Save the presentation\n",
        "prs.save('Model_Performance_Evaluation.pptx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofBx46niVqo9",
        "outputId": "a0d45018-8df4-4c1e-98bd-b0f001329933"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-8abeecc3997b>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final features DataFrame:\n",
            "   NumberOfFollowings  NumberOfFollowers  NumberOfTweets  LengthOfScreenName  \\\n",
            "0                3269               3071             861                   8   \n",
            "1                3269               3071             861                   8   \n",
            "2                3269               3071             861                   8   \n",
            "3                3269               3071             861                   8   \n",
            "4                3269               3071             861                   8   \n",
            "\n",
            "   LengthOfDescriptionInUserProfile  TweetLength  neg  neu  pos  compound  \\\n",
            "0                               132           77  0.0  1.0  0.0       0.0   \n",
            "1                               132           57  0.0  1.0  0.0       0.0   \n",
            "2                               132           57  0.0  1.0  0.0       0.0   \n",
            "3                               132           57  0.0  1.0  0.0       0.0   \n",
            "4                               132           86  0.0  1.0  0.0       0.0   \n",
            "\n",
            "  Label_x  Label_num  \n",
            "0    spam          1  \n",
            "1    spam          1  \n",
            "2    spam          1  \n",
            "3    spam          1  \n",
            "4    spam          1  \n",
            "\n",
            "Checking for NaN and infinity values in features...\n",
            "\n",
            "Number of NaN values in each column of X before imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n",
            "\n",
            "Number of NaN values in each column of X after imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# # Features and target variable\n",
        "# X = processed_tweets[['TweetLength', 'neg', 'neu', 'pos', 'compound']]\n",
        "# y = processed_tweets['Label']\n",
        "\n",
        "# # Convert labels to binary values\n",
        "# y = y.map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# # Split the data into training and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Merge user profile features with processed tweets to include labels and user information\n",
        "tweet_features = pd.merge(processed_tweets, user_profiles, on='UserID', how='left')\n",
        "\n",
        "# Adjust the feature columns based on the available columns in the DataFrame\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets',\n",
        "                   'LengthOfScreenName', 'LengthOfDescriptionInUserProfile',\n",
        "                   'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound', 'Label_x']\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "final_features = tweet_features[[col for col in feature_columns if col in tweet_features.columns]]\n",
        "\n",
        "# Map labels to numerical values if 'Label_x' is available\n",
        "if 'Label_x' in final_features.columns:\n",
        "    final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n",
        "    label_available = True\n",
        "else:\n",
        "    print(\"Warning: 'Label_x' column is missing, cannot map to numerical values.\")\n",
        "    label_available = False\n",
        "\n",
        "# Display the first few rows of the final features\n",
        "print(\"\\nFinal features DataFrame:\")\n",
        "print(final_features.head())\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = final_features.drop(['Label_x', 'Label_num'], axis=1, errors='ignore')\n",
        "y = final_features['Label_num'] if label_available else None\n",
        "\n",
        "# Check for NaN and infinite values\n",
        "print(\"\\nChecking for NaN and infinity values in features...\")\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column\n",
        "print(\"\\nNumber of NaN values in each column of X before imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Fill NaN values with column means\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column after imputation\n",
        "print(\"\\nNumber of NaN values in each column of X after imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Proceed with splitting only if labels are available\n",
        "if label_available:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Define and train the models\n",
        "    models = {\n",
        "        'AdaBoost': AdaBoostClassifier(n_estimators=200, random_state=42),\n",
        "        'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'XGBoost': xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    }\n",
        "\n",
        "    # Function to evaluate the model\n",
        "    def evaluate_model(model, X_test, y_test, y_pred):\n",
        "        print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "        # Create a DataFrame to display predictions and actual labels\n",
        "        evaluation_df = pd.DataFrame({\n",
        "            'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "            'Actual Label': y_test,\n",
        "            'Predicted Label': y_pred\n",
        "        })\n",
        "\n",
        "        # Map numerical labels back to original labels for readability\n",
        "        label_map = {0: 'ham', 1: 'spam'}\n",
        "        evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "        evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "        # Display a sample of the evaluated data\n",
        "        print(\"\\nSample of Evaluated Data:\")\n",
        "        print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "        print(\"\\nTraining AdaBoost...\")\n",
        "        models['AdaBoost'].fit(X_train, y_train)\n",
        "\n",
        "      # Predict with AdaBoost\n",
        "        y_pred_adaboost = models['AdaBoost'].predict(X_test)\n",
        "\n",
        "      # Evaluate AdaBoost\n",
        "        print(\"\\nEvaluating AdaBoost...\")\n",
        "        evaluate_model(models['AdaBoost'], X_test, y_test, y_pred_adaboost)\n",
        "\n",
        "else:\n",
        "    print(\"Skipping model training and evaluation due to missing labels.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTt2UAS5Sj2v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score\n",
        "import xgboost as xgb\n",
        "from nltk.corpus import stopwords\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# STOPWORDS and clean_tweet function\n",
        "STOPWORDS = set(stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    if pd.isnull(tweet):\n",
        "        return \"\"\n",
        "    tweet = str(tweet)\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "    tweet = re.sub(r\"@\\S+\", \"\", tweet)\n",
        "    tweet = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", tweet)\n",
        "    tweet = ' '.join([word for word in tweet.split() if word.lower() not in STOPWORDS])\n",
        "    return tweet\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# Load all the chunk files and concatenate them into a single DataFrame\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# Load user profiles\n",
        "user_profiles = pd.read_csv(os.path.join(data_dir, 'user_profiles.txt'), sep='\\t', header=None, names=[\n",
        "    'UserID', 'NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile', 'TweetsPerDay'])\n",
        "\n",
        "# Merge user profile features with processed tweets to include labels and user information\n",
        "tweet_features = pd.merge(processed_tweets, user_profiles, on='UserID', how='left')\n",
        "\n",
        "# Adjust the feature columns based on the available columns in the DataFrame\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets', 'LengthOfScreenName', 'LengthOfDescriptionInUserProfile', 'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound', 'Label_x']\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "final_features = tweet_features[[col for col in feature_columns if col in tweet_features.columns]]\n",
        "\n",
        "# Map labels to numerical values if 'Label_x' is available\n",
        "if 'Label_x' in final_features.columns:\n",
        "    final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n",
        "    label_available = True\n",
        "else:\n",
        "    print(\"Warning: 'Label_x' column is missing, cannot map to numerical values.\")\n",
        "    label_available = False\n",
        "\n",
        "# Display the first few rows of the final features\n",
        "print(\"\\nFinal features DataFrame:\")\n",
        "print(final_features.head())\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = final_features.drop(['Label_x', 'Label_num'], axis=1, errors='ignore')\n",
        "y = final_features['Label_num'] if label_available else None\n",
        "\n",
        "# Check for NaN and infinite values\n",
        "print(\"\\nChecking for NaN and infinity values in features...\")\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column\n",
        "print(\"\\nNumber of NaN values in each column of X before imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Fill NaN values with column means\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column after imputation\n",
        "print(\"\\nNumber of NaN values in each column of X after imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Proceed with splitting only if labels are available\n",
        "if label_available:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Define and train the models\n",
        "    models = {\n",
        "        'AdaBoost': AdaBoostClassifier(n_estimators=200, random_state=42),\n",
        "        'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'XGBoost': xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "        'GaussianNB': GaussianNB(),\n",
        "        'SVM': SVC(kernel='linear', C=1, random_state=42)\n",
        "    }\n",
        "\n",
        "    # Function to evaluate the model\n",
        "    def evaluate_model(model, X_test, y_test, y_pred):\n",
        "        print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "        print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "        print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "        print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "        print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred))\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "        # Create a DataFrame to display predictions and actual labels\n",
        "        evaluation_df = pd.DataFrame({\n",
        "            'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "            'Actual Label': y_test,\n",
        "            'Predicted Label': y_pred\n",
        "        })\n",
        "\n",
        "        # Map numerical labels back to original labels for readability\n",
        "        label_map = {0: 'ham', 1: 'spam'}\n",
        "        evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "        evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "        # Display a sample of the evaluated data\n",
        "        print(\"\\nSample of Evaluated Data:\")\n",
        "        print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict with the current model\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Evaluate the current model\n",
        "        print(f\"\\nEvaluating {model_name}...\")\n",
        "        evaluate_model(model, X_test, y_test, y_pred)\n",
        "\n",
        "else:\n",
        "    print(\"Skipping model training and evaluation due to missing labels.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFU7HXKpmrZG",
        "outputId": "c74b3c34-9a9b-4522-ae36-a411ba95fa06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training AdaBoost...\n",
            "\n",
            "Model: AdaBoostClassifier\n",
            "Training Accuracy: 0.8951163936461006\n",
            "Testing Accuracy: 0.8946518679964938\n",
            "Classification Report (Testing):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91    981142\n",
            "           1       0.86      0.89      0.88    707298\n",
            "\n",
            "    accuracy                           0.89   1688440\n",
            "   macro avg       0.89      0.89      0.89   1688440\n",
            "weighted avg       0.90      0.89      0.89   1688440\n",
            "\n",
            "Confusion Matrix (Testing):\n",
            " [[882810  98332]\n",
            " [ 79542 627756]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "Training Accuracy for AdaBoost: 0.8951163936461006\n",
            "Testing Accuracy for AdaBoost: 0.8946518679964938\n",
            "\n",
            "Training DecisionTree...\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Training Accuracy: 0.9953803483572696\n",
            "Testing Accuracy: 0.9915347895098434\n",
            "Classification Report (Testing):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix (Testing):\n",
            " [[974893   6249]\n",
            " [  8044 699254]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "Training Accuracy for DecisionTree: 0.9953803483572696\n",
            "Testing Accuracy for DecisionTree: 0.9915347895098434\n",
            "\n",
            "Training RandomForest...\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Training Accuracy: 0.9953790792222029\n",
            "Testing Accuracy: 0.9914785245552107\n",
            "Classification Report (Testing):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    981142\n",
            "           1       0.99      0.99      0.99    707298\n",
            "\n",
            "    accuracy                           0.99   1688440\n",
            "   macro avg       0.99      0.99      0.99   1688440\n",
            "weighted avg       0.99      0.99      0.99   1688440\n",
            "\n",
            "Confusion Matrix (Testing):\n",
            " [[973951   7191]\n",
            " [  7197 700101]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "Training Accuracy for RandomForest: 0.9953790792222029\n",
            "Testing Accuracy for RandomForest: 0.9914785245552107\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Model: XGBClassifier\n",
            "Training Accuracy: 0.936224693764054\n",
            "Testing Accuracy: 0.9355979484020753\n",
            "Classification Report (Testing):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94    981142\n",
            "           1       0.91      0.94      0.92    707298\n",
            "\n",
            "    accuracy                           0.94   1688440\n",
            "   macro avg       0.93      0.94      0.93   1688440\n",
            "weighted avg       0.94      0.94      0.94   1688440\n",
            "\n",
            "Confusion Matrix (Testing):\n",
            " [[913660  67482]\n",
            " [ 41257 666041]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                             Cleaned Tweet Actual Label  \\\n",
            "60347                       FollowFriday awesome tweetlers         spam   \n",
            "976695                        Beverly Hills Virtual Office         spam   \n",
            "4623353                                totally happy right          ham   \n",
            "2160382  Cheapest Young Drivers Insurance4 Means Trimmi...         spam   \n",
            "2402104  Rajoy Zapaterosusto muelteeee Reflexiones de u...          ham   \n",
            "2319806  Nevada Travel Guide Dong Silk Tailor best plac...         spam   \n",
            "325958   Devendra Banhart isnt Foolin wildly intense vi...          ham   \n",
            "1688799                            travel must check email         spam   \n",
            "4606717                            hope feel better girlie          ham   \n",
            "5137027                                                NaN          ham   \n",
            "\n",
            "        Predicted Label  \n",
            "60347              spam  \n",
            "976695             spam  \n",
            "4623353             ham  \n",
            "2160382            spam  \n",
            "2402104             ham  \n",
            "2319806            spam  \n",
            "325958             spam  \n",
            "1688799            spam  \n",
            "4606717             ham  \n",
            "5137027             ham  \n",
            "Training Accuracy for XGBoost: 0.936224693764054\n",
            "Testing Accuracy for XGBoost: 0.9355979484020753\n"
          ]
        }
      ],
      "source": [
        "def eval_model(model, X_train, y_train, X_test, y_test):\n",
        "    # Training accuracy\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    # Testing accuracy\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    # Print accuracies\n",
        "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "    print(\"Training Accuracy:\", train_accuracy)\n",
        "    print(\"Testing Accuracy:\", test_accuracy)\n",
        "    print(\"Classification Report (Testing):\\n\", classification_report(y_test, y_test_pred))\n",
        "    print(\"Confusion Matrix (Testing):\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "    # Create a DataFrame to display predictions and actual labels\n",
        "    evaluation_df = pd.DataFrame({\n",
        "        'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "        'Actual Label': y_test,\n",
        "        'Predicted Label': y_test_pred\n",
        "    })\n",
        "\n",
        "    # Map numerical labels back to original labels for readability\n",
        "    label_map = {0: 'ham', 1: 'spam'}\n",
        "    evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "    evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "    # Display a sample of the evaluated data\n",
        "    print(\"\\nSample of Evaluated Data:\")\n",
        "    print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    train_accuracy, test_accuracy = eval_model(model, X_train, y_train, X_test, y_test)\n",
        "    print(f\"Training Accuracy for {model_name}: {train_accuracy}\")\n",
        "    print(f\"Testing Accuracy for {model_name}: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef3Dye0JV0kf"
      },
      "outputs": [],
      "source": [
        "# # # Initialize models\n",
        "# # models = {\n",
        "# #     'Decision Tree': DecisionTreeClassifier(),\n",
        "# #     'Random Forest': RandomForestClassifier(),\n",
        "# #     'AdaBoost': AdaBoostClassifier(),\n",
        "# #     'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "# # }\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Initialize the SVM classifier\n",
        "# svm_classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# # Train the SVM classifier\n",
        "# svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # Make predictions on the training data\n",
        "# y_pred_train_svm = svm_classifier.predict(X_train_scaled)\n",
        "\n",
        "# # Make predictions on the testing data\n",
        "# y_pred_test_svm = svm_classifier.predict(X_test_scaled)\n",
        "\n",
        "# # Evaluate the SVM classifier\n",
        "# print(f\"\\nModel: {svm_classifier.__class__.__name__}\")\n",
        "# print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train_svm))\n",
        "# print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test_svm))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_svm))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_svm))\n",
        "\n",
        "# # Function to evaluate the model\n",
        "# def evaluate_model_svm(model, X_test, y_test, y_pred):\n",
        "#     print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "#     print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "#     print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "#     print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "#     # Create a DataFrame to display predictions and actual labels\n",
        "#     evaluation_df = pd.DataFrame({\n",
        "#         'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "#         'Actual Label': y_test,\n",
        "#         'Predicted Label': y_pred\n",
        "#     })\n",
        "\n",
        "#     # Map numerical labels back to original labels for readability\n",
        "#     label_map = {0: 'ham', 1: 'spam'}\n",
        "#     evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "#     evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "#     # Display a sample of the evaluated data\n",
        "#     print(\"\\nSample of Evaluated Data:\")\n",
        "#     print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "# # Evaluate the SVM classifier\n",
        "# evaluate_model_svm(svm_classifier, X_test_scaled, y_test, y_pred_test_svm)\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA to reduce the dimensionality\n",
        "pca = PCA(n_components=10)  # Adjust the number of components based on your needs\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Train the SVM classifier\n",
        "import time\n",
        "start_time = time.time()\n",
        "svm_classifier.fit(X_train_pca, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_pred_train_svm = svm_classifier.predict(X_train_pca)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_test_svm = svm_classifier.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the SVM classifier\n",
        "print(f\"\\nModel: {svm_classifier.__class__.__name__}\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train_svm))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_svm))\n",
        "print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model_svm(model, X_test, y_test, y_pred):\n",
        "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Create a DataFrame to display predictions and actual labels\n",
        "    evaluation_df = pd.DataFrame({\n",
        "        'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "        'Actual Label': y_test,\n",
        "        'Predicted Label': y_pred\n",
        "    })\n",
        "\n",
        "    # Map numerical labels back to original labels for readability\n",
        "    label_map = {0: 'ham', 1: 'spam'}\n",
        "    evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "    evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "    # Display a sample of the evaluated data\n",
        "    print(\"\\nSample of Evaluated Data:\")\n",
        "    print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "# Evaluate the SVM classifier\n",
        "evaluate_model_svm(svm_classifier, X_test_pca, y_test, y_pred_test_svm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AxAH4UvXv8X2",
        "outputId": "4c19c8bd-1022-4e7b-b3e9-c0b6a8f82e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the processed tweets:\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt Label  \\\n",
            "0  2009-11-10 15:14:31  spam   \n",
            "1  2009-11-10 15:46:05  spam   \n",
            "2  2009-11-10 15:46:40  spam   \n",
            "3  2009-11-10 15:47:03  spam   \n",
            "4  2009-11-10 15:56:03  spam   \n",
            "\n",
            "                                          CleanTweet  TweetLength  \\\n",
            "0  MELBOURNE ENQUIRY Seeking variety acts end yea...           77   \n",
            "1  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "2  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "3  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "4  Come Burlesque Bootcamp Sydney Saturday 23 Jan...           86   \n",
            "\n",
            "                                     SentimentScores  neg  neu  pos  compound  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "Warning: 'Label_x' column is missing, cannot map to numerical values.\n",
            "\n",
            "Final features DataFrame:\n",
            "   TweetLength  neg  neu  pos  compound\n",
            "0           77  0.0  1.0  0.0       0.0\n",
            "1           57  0.0  1.0  0.0       0.0\n",
            "2           57  0.0  1.0  0.0       0.0\n",
            "3           57  0.0  1.0  0.0       0.0\n",
            "4           86  0.0  1.0  0.0       0.0\n",
            "\n",
            "Checking for NaN and infinity values in features...\n",
            "\n",
            "Number of NaN values in each column of X before imputation:\n",
            " TweetLength    0\n",
            "neg            0\n",
            "neu            0\n",
            "pos            0\n",
            "compound       0\n",
            "dtype: int64\n",
            "\n",
            "Number of NaN values in each column of X after imputation:\n",
            " TweetLength    0\n",
            "neg            0\n",
            "neu            0\n",
            "pos            0\n",
            "compound       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a5f722bcf9ed>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# if label_available:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# KMeans clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m     return list(\n\u001b[0m\u001b[1;32m   2586\u001b[0m         chain.from_iterable(\n\u001b[1;32m   2587\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2585\u001b[0m     return list(\n\u001b[1;32m   2586\u001b[0m         chain.from_iterable(\n\u001b[0;32m-> 2587\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         )\n\u001b[1;32m   2589\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load user profiles (assuming this DataFrame is already loaded in your environment)\n",
        "# user_profiles = ...\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# Load all the chunk files and concatenate them into a single DataFrame\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of the processed tweets:\")\n",
        "print(processed_tweets.head())\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets',\n",
        "                   'LengthOfScreenName', 'LengthOfDescriptionInUserProfile',\n",
        "                   'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound', 'Label_x']\n",
        "final_features = processed_tweets[[col for col in feature_columns if col in processed_tweets.columns]]\n",
        "\n",
        "# Map labels to numerical values if 'Label_x' is available\n",
        "if 'Label_x' in final_features.columns:\n",
        "    final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n",
        "    label_available = True\n",
        "else:\n",
        "    print(\"Warning: 'Label_x' column is missing, cannot map to numerical values.\")\n",
        "    label_available = False\n",
        "\n",
        "# Display the first few rows of the final features\n",
        "print(\"\\nFinal features DataFrame:\")\n",
        "print(final_features.head())\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = final_features.drop(['Label_x', 'Label_num'], axis=1, errors='ignore')\n",
        "y = final_features['Label_num'] if label_available else None\n",
        "\n",
        "# Check for NaN and infinite values\n",
        "print(\"\\nChecking for NaN and infinity values in features...\")\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column\n",
        "print(\"\\nNumber of NaN values in each column of X before imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Fill NaN values with column means\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column after imputation\n",
        "print(\"\\nNumber of NaN values in each column of X after imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Proceed with splitting only if labels are available\n",
        "# if label_available:\n",
        "    # Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # KMeans clustering\n",
        "n_clusters = 2\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "X_train_clusters = kmeans.fit_predict(X_train)\n",
        "X_test_clusters = kmeans.predict(X_test)\n",
        "\n",
        "    # Add cluster labels as a feature\n",
        "X_train['Cluster'] = X_train_clusters\n",
        "X_test['Cluster'] = X_test_clusters\n",
        "\n",
        "    # Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "    # Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Voting Classifier\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "        ('nb', nb_model),\n",
        "        ('dt', dt_model)\n",
        "    ], voting='hard')\n",
        "\n",
        "    # Train the ensemble model\n",
        "print(\"\\nTraining ensemble model...\")\n",
        "\n",
        "start_time = time.time()\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "y_train_pred = ensemble_model.predict(X_train)\n",
        "y_test_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "print(\"\\nEnsemble Model Training Time: {:.2f} seconds\".format(end_time - start_time))\n",
        "\n",
        "print(\"\\nEnsemble Model Training Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
        "print(\"\\nEnsemble Model Testing Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "# else:\n",
        "    #print(\"Skipping model training and evaluation due to missing labels.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9QXtTefV505",
        "outputId": "1c53c6ad-f342-425a-bb52-b6fff1e9f80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the processed tweets:\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt Label  \\\n",
            "0  2009-11-10 15:14:31  spam   \n",
            "1  2009-11-10 15:46:05  spam   \n",
            "2  2009-11-10 15:46:40  spam   \n",
            "3  2009-11-10 15:47:03  spam   \n",
            "4  2009-11-10 15:56:03  spam   \n",
            "\n",
            "                                          CleanTweet  TweetLength  \\\n",
            "0  MELBOURNE ENQUIRY Seeking variety acts end yea...           77   \n",
            "1  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "2  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "3  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "4  Come Burlesque Bootcamp Sydney Saturday 23 Jan...           86   \n",
            "\n",
            "                                     SentimentScores  neg  neu  pos  compound  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Score: 0.2409072244318197\n",
            "\n",
            "Sample of Clustered Data:\n",
            "   UserID                                         CleanTweet  Cluster\n",
            "0    6301  MELBOURNE ENQUIRY Seeking variety acts end yea...        1\n",
            "1    6301  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...        1\n",
            "2    6301  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...        1\n",
            "3    6301  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...        1\n",
            "4    6301  Come Burlesque Bootcamp Sydney Saturday 23 Jan...        1\n",
            "5    6301  21st Century Pinups write girls performing Bla...        1\n",
            "6    6301  Burlesque Bootcamp Coming Sydney Burlesque Boo...        1\n",
            "7    6301  ATTN MELBOURNE group specials available Sunday...        1\n",
            "8    6301  Story lovely Vivi Valentine contract Sugar Blu...        0\n",
            "9    6301  also Black Flamingo Berlin Catherine DLish Tri...        0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "\n",
        "# Load user profiles (assuming this DataFrame is already loaded in your environment)\n",
        "# user_profiles = ...\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in all_files if file.startswith('processed_chunk_') and file.endswith('.csv')]\n",
        "\n",
        "# Load the first 2-3 chunk files and concatenate them into a single DataFrame\n",
        "subset_files = chunk_files[:3]  # Load only the first 3 chunks\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in subset_files], ignore_index=True)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of the processed tweets:\")\n",
        "print(processed_tweets.head())\n",
        "\n",
        "# Merge with user profiles\n",
        "tweet_features = pd.merge(processed_tweets, user_profiles, on='UserID', how='left')\n",
        "\n",
        "# Adjust the feature columns based on the available columns in the DataFrame\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets',\n",
        "                   'LengthOfScreenName', 'LengthOfDescriptionInUserProfile',\n",
        "                   'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound']\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "final_features = tweet_features[[col for col in feature_columns if col in tweet_features.columns]]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(final_features)\n",
        "\n",
        "# Initialize the KMeans clustering classifier\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)  # Assuming 2 clusters for ham and spam\n",
        "\n",
        "# Fit the model\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Predict the clusters\n",
        "clusters = kmeans.predict(X_scaled)\n",
        "\n",
        "# Evaluate the clustering results using silhouette score\n",
        "silhouette_avg = silhouette_score(X_scaled, clusters)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "# Add the cluster labels to the DataFrame\n",
        "tweet_features['Cluster'] = clusters\n",
        "\n",
        "# Display a sample of the clustered data\n",
        "print(\"\\nSample of Clustered Data:\")\n",
        "print(tweet_features[['UserID', 'CleanTweet', 'Cluster']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxXEwcyPvz5",
        "outputId": "b9a16af7-db69-4c67-d5e2-34aedf902d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the processed tweets:\n",
            "   UserID     TweetID                                              Tweet  \\\n",
            "0    6301  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
            "1    6301  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "2    6301  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "3    6301  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
            "4    6301  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
            "\n",
            "             CreatedAt Label  \\\n",
            "0  2009-11-10 15:14:31  spam   \n",
            "1  2009-11-10 15:46:05  spam   \n",
            "2  2009-11-10 15:46:40  spam   \n",
            "3  2009-11-10 15:47:03  spam   \n",
            "4  2009-11-10 15:56:03  spam   \n",
            "\n",
            "                                          CleanTweet  TweetLength  \\\n",
            "0  MELBOURNE ENQUIRY Seeking variety acts end yea...           77   \n",
            "1  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "2  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "3  BURLESQUE BOOTCAMP SYDNEY Open Date tickets av...           57   \n",
            "4  Come Burlesque Bootcamp Sydney Saturday 23 Jan...           86   \n",
            "\n",
            "                                     SentimentScores  neg  neu  pos  compound  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.0  1.0  0.0       0.0  \n",
            "\n",
            "Final features DataFrame:\n",
            "   NumberOfFollowings  NumberOfFollowers  NumberOfTweets  LengthOfScreenName  \\\n",
            "0                3269               3071             861                   8   \n",
            "1                3269               3071             861                   8   \n",
            "2                3269               3071             861                   8   \n",
            "3                3269               3071             861                   8   \n",
            "4                3269               3071             861                   8   \n",
            "\n",
            "   LengthOfDescriptionInUserProfile  TweetLength  neg  neu  pos  compound  \\\n",
            "0                               132           77  0.0  1.0  0.0       0.0   \n",
            "1                               132           57  0.0  1.0  0.0       0.0   \n",
            "2                               132           57  0.0  1.0  0.0       0.0   \n",
            "3                               132           57  0.0  1.0  0.0       0.0   \n",
            "4                               132           86  0.0  1.0  0.0       0.0   \n",
            "\n",
            "  Label_x  Label_num  \n",
            "0    spam          1  \n",
            "1    spam          1  \n",
            "2    spam          1  \n",
            "3    spam          1  \n",
            "4    spam          1  \n",
            "\n",
            "Checking for NaN and infinity values in features...\n",
            "\n",
            "Number of NaN values in each column of X before imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n",
            "\n",
            "Number of NaN values in each column of X after imputation:\n",
            " NumberOfFollowings                  0\n",
            "NumberOfFollowers                   0\n",
            "NumberOfTweets                      0\n",
            "LengthOfScreenName                  0\n",
            "LengthOfDescriptionInUserProfile    0\n",
            "TweetLength                         0\n",
            "neg                                 0\n",
            "neu                                 0\n",
            "pos                                 0\n",
            "compound                            0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-d3355aa405ec>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: GaussianNB\n",
            "Training Accuracy: 0.9592051092083915\n",
            "Testing Accuracy: 0.9582494529540482\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.61      0.22       455\n",
            "           1       1.00      0.96      0.98     45245\n",
            "\n",
            "    accuracy                           0.96     45700\n",
            "   macro avg       0.57      0.78      0.60     45700\n",
            "weighted avg       0.99      0.96      0.97     45700\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  276   179]\n",
            " [ 1729 43516]]\n",
            "\n",
            "Model: GaussianNB\n",
            "Accuracy: 0.9582494529540482\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.61      0.22       455\n",
            "           1       1.00      0.96      0.98     45245\n",
            "\n",
            "    accuracy                           0.96     45700\n",
            "   macro avg       0.57      0.78      0.60     45700\n",
            "weighted avg       0.99      0.96      0.97     45700\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  276   179]\n",
            " [ 1729 43516]]\n",
            "\n",
            "Sample of Evaluated Data:\n",
            "                                            Cleaned Tweet Actual Label  \\\n",
            "122771         Linking Customer Loyalty Social Networking         spam   \n",
            "131316  Case Kim Kardashian Twitter Libel Cookie Diets...         spam   \n",
            "26653   Heres Simple Tips Prevent Deal Content Design ...         spam   \n",
            "378     RT techsailor 8 Engaging Flash Preloaders wort...         spam   \n",
            "144009  Leading Tastebuds Compiling Together Yummiest ...         spam   \n",
            "49097   LOL true true However common sense isnt really...         spam   \n",
            "67439   New blog post Mille Miglia Vintage Car Race En...         spam   \n",
            "60003     happened resellitforprofit offline anybody know         spam   \n",
            "92797                           THINK Twitter male female         spam   \n",
            "8771    RT Want get absurd amounts attention web marke...         spam   \n",
            "\n",
            "       Predicted Label  \n",
            "122771            spam  \n",
            "131316             ham  \n",
            "26653             spam  \n",
            "378               spam  \n",
            "144009            spam  \n",
            "49097             spam  \n",
            "67439             spam  \n",
            "60003             spam  \n",
            "92797             spam  \n",
            "8771              spam  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "\n",
        "# Load user profiles (assuming this DataFrame is already loaded in your environment)\n",
        "# user_profiles = ...\n",
        "\n",
        "# Directory containing the processed chunk files\n",
        "data_dir = '/content/drive/MyDrive/shetty_honeypot'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Filter out the processed chunk files\n",
        "chunk_files = [os.path.join(data_dir, file) for file in chunk_files[:100]]  # Load a few chunk files to create a smaller dataset\n",
        "processed_tweets = pd.concat([pd.read_csv(file) for file in chunk_files], ignore_index=True)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of the processed tweets:\")\n",
        "print(processed_tweets.head())\n",
        "\n",
        "# Merge processed tweets with user profiles on 'UserID'\n",
        "tweet_features = pd.merge(processed_tweets, user_profiles, on='UserID', how='left')\n",
        "\n",
        "# Adjust the feature columns based on the available columns in the DataFrame\n",
        "feature_columns = ['NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets',\n",
        "                   'LengthOfScreenName', 'LengthOfDescriptionInUserProfile',\n",
        "                   'TweetsPerDay', 'TweetLength', 'neg', 'neu', 'pos', 'compound', 'Label_x']\n",
        "\n",
        "# Create a final feature DataFrame with existing columns\n",
        "final_features = tweet_features[[col for col in feature_columns if col in tweet_features.columns]]\n",
        "\n",
        "# Map labels to numerical values if 'Label_x' is available\n",
        "if 'Label_x' in final_features.columns:\n",
        "    final_features['Label_num'] = final_features['Label_x'].map({'ham': 0, 'spam': 1})\n",
        "    label_available = True\n",
        "else:\n",
        "    print(\"Warning: 'Label_x' column is missing, cannot map to numerical values.\")\n",
        "    label_available = False\n",
        "\n",
        "# Display the first few rows of the final features\n",
        "print(\"\\nFinal features DataFrame:\")\n",
        "print(final_features.head())\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = final_features.drop(['Label_x', 'Label_num'], axis=1, errors='ignore')\n",
        "y = final_features['Label_num'] if label_available else None\n",
        "\n",
        "# Check for NaN and infinite values\n",
        "print(\"\\nChecking for NaN and infinity values in features...\")\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column\n",
        "print(\"\\nNumber of NaN values in each column of X before imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Fill NaN values with column means\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Display the number of NaN values in each column after imputation\n",
        "print(\"\\nNumber of NaN values in each column of X after imputation:\\n\", X.isna().sum())\n",
        "\n",
        "# Proceed with splitting only if labels are available\n",
        "if label_available:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Initialize the Naive Bayes classifier\n",
        "    nb_classifier = GaussianNB()\n",
        "\n",
        "    # Train the Naive Bayes classifier\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the training data\n",
        "    y_pred_train_nb = nb_classifier.predict(X_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_test_nb = nb_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the Naive Bayes classifier\n",
        "    print(f\"\\nModel: {nb_classifier.__class__.__name__}\")\n",
        "    print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train_nb))\n",
        "    print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test_nb))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_nb))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_nb))\n",
        "\n",
        "    # Function to evaluate the model\n",
        "    def evaluate_model_nb(model, X_test, y_test, y_pred):\n",
        "        print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "        # Create a DataFrame to display predictions and actual labels\n",
        "        evaluation_df = pd.DataFrame({\n",
        "            'Cleaned Tweet': X_test.index.map(lambda idx: tweet_features.iloc[idx]['CleanTweet']),\n",
        "            'Actual Label': y_test,\n",
        "            'Predicted Label': y_pred\n",
        "        })\n",
        "\n",
        "        # Map numerical labels back to original labels for readability\n",
        "        label_map = {0: 'ham', 1: 'spam'}\n",
        "        evaluation_df['Actual Label'] = evaluation_df['Actual Label'].map(label_map)\n",
        "        evaluation_df['Predicted Label'] = evaluation_df['Predicted Label'].map(label_map)\n",
        "\n",
        "        # Display a sample of the evaluated data\n",
        "        print(\"\\nSample of Evaluated Data:\")\n",
        "        print(evaluation_df.head(10))  # Display the first 10 rows\n",
        "\n",
        "    # Evaluate the Naive Bayes classifier\n",
        "    evaluate_model_nb(nb_classifier, X_test, y_test, y_pred_test_nb)\n",
        "else:\n",
        "    print(\"Skipping model training and evaluation due to missing labels.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}